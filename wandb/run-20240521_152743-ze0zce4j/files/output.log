
  0%|                                                                                                        | 0/22490 [00:00<?, ?it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale










  0%|▍                                                                                            | 99/22490 [00:23<1:16:47,  4.86it/s]










  1%|▊                                                                                           | 196/22490 [00:43<1:16:32,  4.85it/s]










  1%|█▏                                                                                          | 293/22490 [01:03<1:18:15,  4.73it/s]











  2%|█▋                                                                                          | 399/22490 [01:26<1:15:46,  4.86it/s]










  2%|██                                                                                          | 496/22490 [01:46<1:16:23,  4.80it/s]










  3%|██▍                                                                                         | 593/22490 [02:06<1:21:51,  4.46it/s]











  3%|██▊                                                                                         | 700/22490 [02:28<1:15:29,  4.81it/s]










  4%|███▎                                                                                        | 796/22490 [02:48<1:16:31,  4.72it/s]











  4%|███▋                                                                                        | 903/22490 [03:10<1:14:45,  4.81it/s]










  4%|████                                                                                        | 999/22490 [03:30<1:17:34,  4.62it/s]










  5%|████▍                                                                                      | 1095/22490 [03:50<1:23:41,  4.26it/s]











  5%|████▊                                                                                      | 1201/22490 [04:12<1:21:20,  4.36it/s]










  6%|█████▏                                                                                     | 1296/22490 [04:32<1:12:23,  4.88it/s]










  6%|█████▋                                                                                     | 1393/22490 [04:52<1:11:57,  4.89it/s]











  7%|██████                                                                                     | 1499/22490 [05:14<1:12:04,  4.85it/s]










  7%|██████▍                                                                                    | 1595/22490 [05:34<1:11:37,  4.86it/s]











  8%|██████▉                                                                                    | 1702/22490 [05:56<1:11:07,  4.87it/s]










  8%|███████▎                                                                                   | 1799/22490 [06:16<1:11:19,  4.83it/s]










  8%|███████▋                                                                                   | 1895/22490 [06:36<1:10:28,  4.87it/s]











  9%|████████                                                                                   | 2002/22490 [06:58<1:10:05,  4.87it/s]










  9%|████████▍                                                                                  | 2099/22490 [07:18<1:09:31,  4.89it/s]










 10%|████████▉                                                                                  | 2196/22490 [07:38<1:08:41,  4.92it/s]





 10%|█████████                                                                                  | 2248/22490 [07:49<1:08:56,  4.89it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 10%|█████████                                                                                  | 2249/22490 [07:49<1:22:40,  4.08it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale




 10%|█████████▎                                                                                 | 2297/22490 [08:04<1:09:04,  4.87it/s]











 11%|█████████▋                                                                                 | 2403/22490 [08:26<1:08:59,  4.85it/s]










 11%|██████████                                                                                 | 2500/22490 [08:46<1:08:45,  4.85it/s]










 12%|██████████▌                                                                                | 2597/22490 [09:07<1:08:23,  4.85it/s]











 12%|██████████▉                                                                                | 2701/22490 [09:28<1:08:18,  4.83it/s]










 12%|███████████▎                                                                               | 2798/22490 [09:48<1:07:39,  4.85it/s]










 13%|███████████▋                                                                               | 2895/22490 [10:08<1:07:00,  4.87it/s]











 13%|████████████▏                                                                              | 3001/22490 [10:30<1:06:55,  4.85it/s]










 14%|████████████▌                                                                              | 3098/22490 [10:50<1:06:31,  4.86it/s]










 14%|████████████▉                                                                              | 3195/22490 [11:10<1:05:57,  4.88it/s]











 15%|█████████████▎                                                                             | 3302/22490 [11:33<1:05:53,  4.85it/s]










 15%|█████████████▊                                                                             | 3399/22490 [11:53<1:05:27,  4.86it/s]










 16%|██████████████▏                                                                            | 3496/22490 [12:13<1:04:51,  4.88it/s]











 16%|██████████████▌                                                                            | 3602/22490 [12:35<1:04:56,  4.85it/s]










 16%|██████████████▉                                                                            | 3699/22490 [12:55<1:04:30,  4.85it/s]










 17%|███████████████▎                                                                           | 3796/22490 [13:15<1:03:49,  4.88it/s]











 17%|███████████████▊                                                                           | 3902/22490 [13:37<1:04:21,  4.81it/s]










 18%|████████████████▏                                                                          | 3999/22490 [13:57<1:03:27,  4.86it/s]










 18%|████████████████▌                                                                          | 4096/22490 [14:17<1:03:04,  4.86it/s]











 19%|████████████████▉                                                                          | 4200/22490 [14:39<1:02:50,  4.85it/s]










 19%|█████████████████▍                                                                         | 4297/22490 [14:59<1:02:16,  4.87it/s]










 20%|█████████████████▊                                                                         | 4394/22490 [15:19<1:02:15,  4.84it/s]










 20%|██████████████████▏                                                                        | 4497/22490 [15:40<1:01:09,  4.90it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 20%|██████████████████▏                                                                        | 4498/22490 [15:40<1:13:44,  4.07it/s]
 20%|██████████████████▏                                                                        | 4498/22490 [15:40<1:13:44,  4.07it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale










 20%|██████████████████▌                                                                        | 4601/22490 [16:07<1:01:33,  4.84it/s]










 21%|███████████████████                                                                        | 4698/22490 [16:27<1:01:09,  4.85it/s]










 21%|███████████████████▍                                                                       | 4794/22490 [16:47<1:00:37,  4.86it/s]











 22%|███████████████████▊                                                                       | 4901/22490 [17:09<1:00:23,  4.85it/s]










 22%|████████████████████▋                                                                        | 4998/22490 [17:29<59:42,  4.88it/s]










 23%|█████████████████████                                                                        | 5095/22490 [17:49<59:45,  4.85it/s]











 23%|█████████████████████                                                                      | 5200/22490 [18:11<1:00:02,  4.80it/s]










 24%|█████████████████████▉                                                                       | 5295/22490 [18:31<59:45,  4.80it/s]











 24%|██████████████████████▎                                                                      | 5400/22490 [18:53<59:24,  4.79it/s]











 24%|██████████████████████▊                                                                      | 5505/22490 [19:16<59:07,  4.79it/s]










 25%|███████████████████████▏                                                                     | 5600/22490 [19:36<58:45,  4.79it/s]











 25%|███████████████████████▌                                                                     | 5705/22490 [19:58<58:21,  4.79it/s]










 26%|███████████████████████▉                                                                     | 5800/22490 [20:18<57:07,  4.87it/s]










 26%|████████████████████████▎                                                                    | 5894/22490 [20:37<57:56,  4.77it/s]











 27%|████████████████████████▊                                                                    | 6000/22490 [20:59<56:48,  4.84it/s]










 27%|█████████████████████████▏                                                                   | 6096/22490 [21:19<57:15,  4.77it/s]











 28%|█████████████████████████▋                                                                   | 6201/22490 [21:41<57:12,  4.75it/s]










 28%|██████████████████████████                                                                   | 6296/22490 [22:01<57:47,  4.67it/s]











 28%|██████████████████████████▍                                                                  | 6402/22490 [22:24<55:40,  4.82it/s]










 29%|██████████████████████████▊                                                                  | 6498/22490 [22:44<55:23,  4.81it/s]










 29%|██████████████████████████▋                                                                | 6596/22490 [23:04<1:01:28,  4.31it/s]











 30%|███████████████████████████▋                                                                 | 6703/22490 [23:26<54:28,  4.83it/s]




 30%|███████████████████████████▉                                                                 | 6746/22490 [23:35<53:33,  4.90it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 30%|███████████████████████████▎                                                               | 6747/22490 [23:35<1:03:45,  4.11it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 30%|████████████████████████████▏                                                                | 6804/22490 [23:52<55:13,  4.73it/s]










 31%|████████████████████████████▌                                                                | 6902/22490 [24:12<55:20,  4.69it/s]










 31%|████████████████████████████▉                                                                | 7000/22490 [24:32<52:43,  4.90it/s]










 32%|█████████████████████████████▎                                                               | 7095/22490 [24:52<52:45,  4.86it/s]











 32%|█████████████████████████████▊                                                               | 7202/22490 [25:14<51:58,  4.90it/s]










 32%|██████████████████████████████▏                                                              | 7299/22490 [25:34<51:53,  4.88it/s]










 33%|██████████████████████████████▌                                                              | 7396/22490 [25:54<51:37,  4.87it/s]











 33%|███████████████████████████████                                                              | 7503/22490 [26:16<51:33,  4.84it/s]










 34%|███████████████████████████████▍                                                             | 7600/22490 [26:36<50:55,  4.87it/s]










 34%|███████████████████████████████▊                                                             | 7697/22490 [26:56<50:31,  4.88it/s]











 35%|████████████████████████████████▎                                                            | 7803/22490 [27:18<50:21,  4.86it/s]










 35%|████████████████████████████████▋                                                            | 7900/22490 [27:38<50:18,  4.83it/s]










 36%|█████████████████████████████████                                                            | 7997/22490 [27:58<49:39,  4.86it/s]











 36%|█████████████████████████████████▌                                                           | 8103/22490 [28:20<50:05,  4.79it/s]










 36%|█████████████████████████████████▉                                                           | 8199/22490 [28:40<49:47,  4.78it/s]











 37%|██████████████████████████████████▎                                                          | 8305/22490 [29:03<48:38,  4.86it/s]










 37%|██████████████████████████████████▋                                                          | 8399/22490 [29:22<48:16,  4.87it/s]










 38%|███████████████████████████████████▏                                                         | 8496/22490 [29:42<48:01,  4.86it/s]











 38%|███████████████████████████████████▌                                                         | 8602/22490 [30:04<47:43,  4.85it/s]










 39%|███████████████████████████████████▉                                                         | 8699/22490 [30:24<47:14,  4.87it/s]










 39%|████████████████████████████████████▎                                                        | 8795/22490 [30:44<47:27,  4.81it/s]











 40%|████████████████████████████████████▊                                                        | 8901/22490 [31:06<47:13,  4.80it/s]









 40%|█████████████████████████████████████▏                                                       | 8995/22490 [31:26<45:51,  4.90it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 40%|█████████████████████████████████████▏                                                       | 8996/22490 [31:26<56:17,  4.00it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 40%|████████████████████████████████████▍                                                      | 9002/22490 [31:33<1:44:20,  2.15it/s]










 40%|█████████████████████████████████████▋                                                       | 9099/22490 [31:53<46:00,  4.85it/s]










 41%|██████████████████████████████████████                                                       | 9196/22490 [32:13<45:13,  4.90it/s]











 41%|██████████████████████████████████████▍                                                      | 9303/22490 [32:35<45:18,  4.85it/s]










 42%|██████████████████████████████████████▊                                                      | 9399/22490 [32:55<44:58,  4.85it/s]











 42%|███████████████████████████████████████▎                                                     | 9502/22490 [33:16<45:58,  4.71it/s]










 43%|███████████████████████████████████████▋                                                     | 9597/22490 [33:36<44:49,  4.79it/s]











 43%|████████████████████████████████████████                                                     | 9702/22490 [33:59<44:28,  4.79it/s]










 44%|████████████████████████████████████████▌                                                    | 9798/22490 [34:19<43:54,  4.82it/s]










 44%|████████████████████████████████████████▉                                                    | 9895/22490 [34:39<43:24,  4.84it/s]











 44%|████████████████████████████████████████▉                                                   | 10002/22490 [35:01<42:41,  4.88it/s]










 45%|█████████████████████████████████████████▎                                                  | 10099/22490 [35:21<42:25,  4.87it/s]










 45%|█████████████████████████████████████████▋                                                  | 10196/22490 [35:41<42:18,  4.84it/s]











 46%|██████████████████████████████████████████▏                                                 | 10303/22490 [36:03<41:40,  4.87it/s]










 46%|██████████████████████████████████████████▌                                                 | 10400/22490 [36:23<41:33,  4.85it/s]










 47%|██████████████████████████████████████████▉                                                 | 10497/22490 [36:43<42:33,  4.70it/s]











 47%|███████████████████████████████████████████▎                                                | 10602/22490 [37:05<42:22,  4.68it/s]










 48%|███████████████████████████████████████████▊                                                | 10700/22490 [37:25<42:45,  4.60it/s]










 48%|████████████████████████████████████████████▏                                               | 10798/22490 [37:45<39:52,  4.89it/s]











 48%|████████████████████████████████████████████▌                                               | 10905/22490 [38:07<39:29,  4.89it/s]










 49%|█████████████████████████████████████████████                                               | 11004/22490 [38:27<39:09,  4.89it/s]










 49%|█████████████████████████████████████████████▍                                              | 11101/22490 [38:47<38:53,  4.88it/s]










 50%|█████████████████████████████████████████████▊                                              | 11199/22490 [39:07<38:16,  4.92it/s]




 50%|█████████████████████████████████████████████▉                                              | 11244/22490 [39:17<38:06,  4.92it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 50%|██████████████████████████████████████████████                                              | 11245/22490 [39:17<46:09,  4.06it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 50%|██████████████████████████████████████████████▏                                             | 11300/22490 [39:34<37:57,  4.91it/s]










 51%|██████████████████████████████████████████████▌                                             | 11397/22490 [39:54<38:43,  4.78it/s]











 51%|███████████████████████████████████████████████                                             | 11501/22490 [40:15<37:34,  4.87it/s]










 52%|███████████████████████████████████████████████▍                                            | 11599/22490 [40:35<37:00,  4.90it/s]










 52%|███████████████████████████████████████████████▊                                            | 11697/22490 [40:55<36:36,  4.91it/s]











 52%|████████████████████████████████████████████████▎                                           | 11804/22490 [41:17<36:24,  4.89it/s]










 53%|████████████████████████████████████████████████▋                                           | 11902/22490 [41:38<36:02,  4.90it/s]










 53%|█████████████████████████████████████████████████                                           | 11999/22490 [41:57<35:37,  4.91it/s]










 54%|█████████████████████████████████████████████████▍                                          | 12097/22490 [42:18<35:15,  4.91it/s]











 54%|█████████████████████████████████████████████████▉                                          | 12204/22490 [42:40<35:07,  4.88it/s]










 55%|██████████████████████████████████████████████████▎                                         | 12302/22490 [43:00<34:52,  4.87it/s]










 55%|██████████████████████████████████████████████████▋                                         | 12397/22490 [43:19<34:28,  4.88it/s]











 56%|███████████████████████████████████████████████████▏                                        | 12505/22490 [43:42<34:05,  4.88it/s]










 56%|███████████████████████████████████████████████████▌                                        | 12602/22490 [44:02<33:48,  4.87it/s]










 56%|███████████████████████████████████████████████████▉                                        | 12700/22490 [44:22<33:17,  4.90it/s]











 57%|████████████████████████████████████████████████████▍                                       | 12807/22490 [44:44<32:53,  4.91it/s]










 57%|████████████████████████████████████████████████████▊                                       | 12905/22490 [45:04<32:42,  4.88it/s]










 58%|█████████████████████████████████████████████████████▏                                      | 13002/22490 [45:24<32:24,  4.88it/s]










 58%|█████████████████████████████████████████████████████▌                                      | 13100/22490 [45:44<32:03,  4.88it/s]











 59%|██████████████████████████████████████████████████████                                      | 13207/22490 [46:06<31:46,  4.87it/s]










 59%|██████████████████████████████████████████████████████▍                                     | 13302/22490 [46:26<31:28,  4.86it/s]










 60%|██████████████████████████████████████████████████████▊                                     | 13400/22490 [46:46<31:04,  4.87it/s]









 60%|███████████████████████████████████████████████████████▏                                    | 13493/22490 [47:05<30:28,  4.92it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 60%|███████████████████████████████████████████████████████▏                                    | 13494/22490 [47:05<36:57,  4.06it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 60%|███████████████████████████████████████████████████████▏                                    | 13501/22490 [47:12<58:36,  2.56it/s]










 60%|███████████████████████████████████████████████████████▋                                    | 13599/22490 [47:32<30:14,  4.90it/s]











 61%|████████████████████████████████████████████████████████                                    | 13706/22490 [47:54<29:52,  4.90it/s]










 61%|████████████████████████████████████████████████████████▍                                   | 13804/22490 [48:14<29:35,  4.89it/s]










 62%|████████████████████████████████████████████████████████▊                                   | 13902/22490 [48:34<29:18,  4.88it/s]










 62%|█████████████████████████████████████████████████████████▎                                  | 14000/22490 [48:54<28:57,  4.89it/s]











 63%|█████████████████████████████████████████████████████████▋                                  | 14107/22490 [49:16<28:37,  4.88it/s]










 63%|██████████████████████████████████████████████████████████                                  | 14204/22490 [49:36<28:17,  4.88it/s]










 64%|██████████████████████████████████████████████████████████▍                                 | 14300/22490 [49:56<28:13,  4.84it/s]










 64%|██████████████████████████████████████████████████████████▉                                 | 14398/22490 [50:16<27:34,  4.89it/s]











 64%|███████████████████████████████████████████████████████████▎                                | 14504/22490 [50:38<32:29,  4.10it/s]










 65%|███████████████████████████████████████████████████████████▋                                | 14602/22490 [50:58<26:58,  4.87it/s]










 65%|████████████████████████████████████████████████████████████▏                               | 14700/22490 [51:18<26:31,  4.90it/s]










 66%|████████████████████████████████████████████████████████████▌                               | 14798/22490 [51:39<26:11,  4.89it/s]











 66%|████████████████████████████████████████████████████████████▉                               | 14905/22490 [52:01<25:56,  4.87it/s]










 67%|█████████████████████████████████████████████████████████████▎                              | 15003/22490 [52:21<25:36,  4.87it/s]










 67%|█████████████████████████████████████████████████████████████▊                              | 15100/22490 [52:41<25:12,  4.89it/s]











 68%|██████████████████████████████████████████████████████████████▏                             | 15205/22490 [53:02<24:48,  4.89it/s]










 68%|██████████████████████████████████████████████████████████████▌                             | 15303/22490 [53:22<24:30,  4.89it/s]










 68%|██████████████████████████████████████████████████████████████▉                             | 15400/22490 [53:42<24:13,  4.88it/s]










 69%|███████████████████████████████████████████████████████████████▍                            | 15498/22490 [54:03<23:50,  4.89it/s]











 69%|███████████████████████████████████████████████████████████████▊                            | 15605/22490 [54:25<23:31,  4.88it/s]










 70%|████████████████████████████████████████████████████████████████▏                           | 15702/22490 [54:45<23:03,  4.91it/s]




 70%|████████████████████████████████████████████████████████████████▍                           | 15742/22490 [54:53<23:22,  4.81it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 70%|████████████████████████████████████████████████████████████████▍                           | 15743/22490 [54:53<28:14,  3.98it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 70%|████████████████████████████████████████████████████████████████▋                           | 15802/22490 [55:11<22:45,  4.90it/s]










 71%|█████████████████████████████████████████████████████████████████                           | 15900/22490 [55:31<22:25,  4.90it/s]











 71%|█████████████████████████████████████████████████████████████████▍                          | 16008/22490 [55:53<22:04,  4.89it/s]










 72%|█████████████████████████████████████████████████████████████████▊                          | 16103/22490 [56:13<21:46,  4.89it/s]










 72%|██████████████████████████████████████████████████████████████████▎                         | 16200/22490 [56:33<21:25,  4.89it/s]











 73%|██████████████████████████████████████████████████████████████████▋                         | 16308/22490 [56:55<21:09,  4.87it/s]










 73%|███████████████████████████████████████████████████████████████████                         | 16405/22490 [57:15<20:41,  4.90it/s]










 73%|███████████████████████████████████████████████████████████████████▌                        | 16503/22490 [57:35<20:26,  4.88it/s]










 74%|███████████████████████████████████████████████████████████████████▉                        | 16601/22490 [57:55<20:03,  4.89it/s]











 74%|████████████████████████████████████████████████████████████████████▎                       | 16708/22490 [58:17<19:41,  4.89it/s]










 75%|████████████████████████████████████████████████████████████████████▋                       | 16806/22490 [58:37<19:21,  4.89it/s]










 75%|█████████████████████████████████████████████████████████████████████▏                      | 16904/22490 [58:57<19:03,  4.89it/s]










 76%|█████████████████████████████████████████████████████████████████████▌                      | 16999/22490 [59:17<18:41,  4.90it/s]











 76%|█████████████████████████████████████████████████████████████████████▉                      | 17106/22490 [59:39<18:20,  4.89it/s]










 76%|██████████████████████████████████████████████████████████████████████▍                     | 17204/22490 [59:59<18:03,  4.88it/s]










 77%|█████████████████████████████████████████████████████████████████████▏                    | 17301/22490 [1:00:19<17:43,  4.88it/s]











 77%|█████████████████████████████████████████████████████████████████████▋                    | 17408/22490 [1:00:41<17:23,  4.87it/s]










 78%|██████████████████████████████████████████████████████████████████████                    | 17503/22490 [1:01:01<17:58,  4.62it/s]











 78%|██████████████████████████████████████████████████████████████████████▍                   | 17608/22490 [1:01:23<16:57,  4.80it/s]










 79%|██████████████████████████████████████████████████████████████████████▊                   | 17703/22490 [1:01:43<16:40,  4.78it/s]











 79%|███████████████████████████████████████████████████████████████████████▎                  | 17808/22490 [1:02:05<16:03,  4.86it/s]










 80%|███████████████████████████████████████████████████████████████████████▋                  | 17905/22490 [1:02:26<15:48,  4.84it/s]









 80%|███████████████████████████████████████████████████████████████████████▉                  | 17991/22490 [1:02:43<15:16,  4.91it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 80%|████████████████████████████████████████████████████████████████████████                  | 17992/22490 [1:02:44<18:24,  4.07it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 80%|████████████████████████████████████████████████████████████████████████                  | 18002/22490 [1:02:51<20:27,  3.66it/s]










 80%|████████████████████████████████████████████████████████████████████████▍                 | 18100/22490 [1:03:11<15:01,  4.87it/s]











 81%|████████████████████████████████████████████████████████████████████████▊                 | 18207/22490 [1:03:33<14:32,  4.91it/s]










 81%|█████████████████████████████████████████████████████████████████████████▎                | 18305/22490 [1:03:53<14:19,  4.87it/s]










 82%|█████████████████████████████████████████████████████████████████████████▋                | 18403/22490 [1:04:14<14:32,  4.68it/s]










 82%|██████████████████████████████████████████████████████████████████████████                | 18501/22490 [1:04:34<13:45,  4.83it/s]











 83%|██████████████████████████████████████████████████████████████████████████▍               | 18608/22490 [1:04:56<13:25,  4.82it/s]










 83%|██████████████████████████████████████████████████████████████████████████▊               | 18706/22490 [1:05:16<13:41,  4.61it/s]










 84%|███████████████████████████████████████████████████████████████████████████▏              | 18804/22490 [1:05:36<12:35,  4.88it/s]










 84%|███████████████████████████████████████████████████████████████████████████▋              | 18901/22490 [1:05:56<12:16,  4.87it/s]











 85%|████████████████████████████████████████████████████████████████████████████              | 19008/22490 [1:06:18<12:56,  4.49it/s]










 85%|████████████████████████████████████████████████████████████████████████████▍             | 19106/22490 [1:06:38<11:31,  4.89it/s]










 85%|████████████████████████████████████████████████████████████████████████████▊             | 19204/22490 [1:06:58<11:10,  4.90it/s]









 86%|█████████████████████████████████████████████████████████████████████████████▏            | 19292/22490 [1:07:16<10:53,  4.90it/s]











 86%|█████████████████████████████████████████████████████████████████████████████▌            | 19397/22490 [1:07:38<10:33,  4.88it/s]










 87%|██████████████████████████████████████████████████████████████████████████████            | 19494/22490 [1:07:58<10:13,  4.88it/s]










 87%|██████████████████████████████████████████████████████████████████████████████▍           | 19592/22490 [1:08:18<09:53,  4.88it/s]











 88%|██████████████████████████████████████████████████████████████████████████████▊           | 19699/22490 [1:08:40<09:28,  4.91it/s]










 88%|███████████████████████████████████████████████████████████████████████████████▏          | 19797/22490 [1:09:00<09:12,  4.87it/s]










 88%|███████████████████████████████████████████████████████████████████████████████▌          | 19894/22490 [1:09:20<08:50,  4.89it/s]










 89%|████████████████████████████████████████████████████████████████████████████████          | 19992/22490 [1:09:40<08:30,  4.89it/s]











 89%|████████████████████████████████████████████████████████████████████████████████▍         | 20099/22490 [1:10:02<08:08,  4.89it/s]










 90%|████████████████████████████████████████████████████████████████████████████████▊         | 20196/22490 [1:10:22<07:46,  4.92it/s]




 90%|████████████████████████████████████████████████████████████████████████████████▉         | 20240/22490 [1:10:31<07:37,  4.92it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 90%|█████████████████████████████████████████████████████████████████████████████████         | 20241/22490 [1:10:32<10:38,  3.52it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 90%|█████████████████████████████████████████████████████████████████████████████████▏        | 20298/22490 [1:10:48<07:25,  4.92it/s]










 91%|█████████████████████████████████████████████████████████████████████████████████▌        | 20396/22490 [1:11:09<07:06,  4.91it/s]










 91%|██████████████████████████████████████████████████████████████████████████████████        | 20493/22490 [1:11:28<06:46,  4.91it/s]











 92%|██████████████████████████████████████████████████████████████████████████████████▍       | 20598/22490 [1:11:50<06:27,  4.88it/s]










 92%|██████████████████████████████████████████████████████████████████████████████████▊       | 20696/22490 [1:12:10<06:08,  4.87it/s]










 92%|███████████████████████████████████████████████████████████████████████████████████▏      | 20793/22490 [1:12:30<05:46,  4.89it/s]










 93%|███████████████████████████████████████████████████████████████████████████████████▌      | 20891/22490 [1:12:50<05:26,  4.90it/s]











 93%|████████████████████████████████████████████████████████████████████████████████████      | 20998/22490 [1:13:12<05:04,  4.90it/s]










 94%|████████████████████████████████████████████████████████████████████████████████████▍     | 21096/22490 [1:13:33<04:46,  4.87it/s]










 94%|████████████████████████████████████████████████████████████████████████████████████▊     | 21194/22490 [1:13:53<04:24,  4.91it/s]










 95%|█████████████████████████████████████████████████████████████████████████████████████▏    | 21291/22490 [1:14:13<04:05,  4.89it/s]











 95%|█████████████████████████████████████████████████████████████████████████████████████▋    | 21399/22490 [1:14:35<03:42,  4.90it/s]










 96%|██████████████████████████████████████████████████████████████████████████████████████    | 21494/22490 [1:14:54<03:23,  4.89it/s]










 96%|██████████████████████████████████████████████████████████████████████████████████████▍   | 21591/22490 [1:15:14<03:04,  4.87it/s]











 96%|██████████████████████████████████████████████████████████████████████████████████████▊   | 21699/22490 [1:15:37<02:41,  4.88it/s]










 97%|███████████████████████████████████████████████████████████████████████████████████████▏  | 21796/22490 [1:15:57<02:21,  4.89it/s]










 97%|███████████████████████████████████████████████████████████████████████████████████████▌  | 21894/22490 [1:16:17<02:01,  4.91it/s]











 98%|████████████████████████████████████████████████████████████████████████████████████████  | 22001/22490 [1:16:39<01:40,  4.85it/s]










 98%|████████████████████████████████████████████████████████████████████████████████████████▍ | 22098/22490 [1:16:59<01:20,  4.84it/s]










 99%|████████████████████████████████████████████████████████████████████████████████████████▊ | 22196/22490 [1:17:19<01:01,  4.82it/s]










 99%|█████████████████████████████████████████████████████████████████████████████████████████▏| 22294/22490 [1:17:39<00:47,  4.15it/s]











100%|█████████████████████████████████████████████████████████████████████████████████████████▋| 22398/22490 [1:18:01<00:20,  4.46it/s]









100%|█████████████████████████████████████████████████████████████████████████████████████████▉| 22489/22490 [1:18:19<00:00,  4.89it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
100%|██████████████████████████████████████████████████████████████████████████████████████████| 22490/22490 [1:18:20<00:00,  4.01it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████| 22490/22490 [1:18:23<00:00,  4.78it/s]

Testing lang af-ZA: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.51it/s]
Testing lang am-ET: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
Testing lang ar-SA: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.57it/s]

Testing lang az-AZ: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang bn-BD: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang ca-ES: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang cy-GB: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang da-DK: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang de-DE: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.59it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang el-GR: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.57it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang en-US: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang es-ES: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang fa-IR: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang fi-FI: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang fr-FR: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang he-IL: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.46it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang hi-IN: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:03<00:00, 15.57it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang hu-HU: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang hy-AM: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang id-ID: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang is-IS: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.59it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang it-IT: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
  _warn_prf(average, modifier, msg_start, len(result))█████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.59it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))█████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.59it/s]
Testing lang jv-ID:  81%|███████████████████████████████████████████████████████████████               | 38/47 [00:02<00:00, 16.44it/s]
Testing lang ka-GE:  51%|███████████████████████████████████████▊                                      | 24/47 [00:01<00:01, 16.41it/s]
Testing lang km-KH:  17%|█████████████▍                                                                 | 8/47 [00:00<00:02, 16.39it/s]
Testing lang km-KH:  85%|██████████████████████████████████████████████████████████████████▍           | 40/47 [00:02<00:00, 16.42it/s]
Testing lang kn-IN:  51%|███████████████████████████████████████▊                                      | 24/47 [00:01<00:01, 16.52it/s]
Testing lang ko-KR:  21%|████████████████▌                                                             | 10/47 [00:00<00:02, 16.42it/s]
Testing lang ko-KR:  89%|█████████████████████████████████████████████████████████████████████▋        | 42/47 [00:02<00:00, 16.43it/s]
Testing lang lv-LV:  55%|███████████████████████████████████████████▏                                  | 26/47 [00:01<00:01, 16.40it/s]
Testing lang ml-IN:   4%|███▎                                                                           | 2/47 [00:00<00:02, 16.51it/s]
Testing lang ml-IN:  77%|███████████████████████████████████████████████████████████▋                  | 36/47 [00:02<00:00, 16.44it/s]
Testing lang mn-MN:  38%|█████████████████████████████▊                                                | 18/47 [00:01<00:01, 16.52it/s]
Testing lang ms-MY:   4%|███▎                                                                           | 2/47 [00:00<00:02, 16.52it/s]
Testing lang ms-MY:  77%|███████████████████████████████████████████████████████████▋                  | 36/47 [00:02<00:00, 16.42it/s]
Testing lang my-MM:  43%|█████████████████████████████████▏                                            | 20/47 [00:01<00:01, 16.41it/s]
Testing lang nb-NO:   9%|██████▋                                                                        | 4/47 [00:00<00:02, 16.34it/s]
Testing lang nb-NO:  77%|███████████████████████████████████████████████████████████▋                  | 36/47 [00:02<00:00, 16.43it/s]
Testing lang nl-NL:  43%|█████████████████████████████████▏                                            | 20/47 [00:01<00:01, 16.43it/s]
Testing lang pl-PL:   9%|██████▋                                                                        | 4/47 [00:00<00:02, 16.38it/s]
Testing lang pl-PL:  77%|███████████████████████████████████████████████████████████▋                  | 36/47 [00:02<00:00, 16.42it/s]
Testing lang pt-PT:  43%|█████████████████████████████████▏                                            | 20/47 [00:01<00:01, 16.42it/s]
Testing lang ro-RO:   4%|███▎                                                                           | 2/47 [00:00<00:02, 16.48it/s]
Testing lang ro-RO:  77%|███████████████████████████████████████████████████████████▋                  | 36/47 [00:02<00:00, 16.44it/s]
Testing lang ru-RU:  43%|█████████████████████████████████▏                                            | 20/47 [00:01<00:01, 16.44it/s]
Testing lang sl-SL:   4%|███▎                                                                           | 2/47 [00:00<00:02, 16.48it/s]
Testing lang sl-SL:  77%|███████████████████████████████████████████████████████████▋                  | 36/47 [00:02<00:00, 16.52it/s]
Testing lang sq-AL:  38%|█████████████████████████████▊                                                | 18/47 [00:01<00:01, 16.52it/s]
Testing lang sv-SE:   4%|███▎                                                                           | 2/47 [00:00<00:02, 16.48it/s]
Testing lang sv-SE:  72%|████████████████████████████████████████████████████████▍                     | 34/47 [00:02<00:00, 16.43it/s]
Testing lang sw-KE:  38%|█████████████████████████████▊                                                | 18/47 [00:01<00:01, 16.44it/s]
Testing lang ta-IN:   0%|                                                                                       | 0/47 [00:00<?, ?it/s]
Testing lang ta-IN:  72%|████████████████████████████████████████████████████████▍                     | 34/47 [00:02<00:00, 16.52it/s]
Testing lang te-IN:  34%|██████████████████████████▌                                                   | 16/47 [00:00<00:01, 16.44it/s]
Testing lang te-IN: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
Testing lang th-TH:  68%|█████████████████████████████████████████████████████                         | 32/47 [00:01<00:00, 16.20it/s]
Testing lang tl-PH:  30%|███████████████████████▏                                                      | 14/47 [00:00<00:02, 16.43it/s]
Testing lang tl-PH: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.59it/s]
Testing lang tr-TR:  64%|█████████████████████████████████████████████████▊                            | 30/47 [00:01<00:01, 16.42it/s]
Testing lang ur-PK:  26%|███████████████████▉                                                          | 12/47 [00:00<00:02, 16.42it/s]
Testing lang ur-PK:  94%|█████████████████████████████████████████████████████████████████████████     | 44/47 [00:02<00:00, 16.43it/s]
Testing lang vi-VN:  60%|██████████████████████████████████████████████▍                               | 28/47 [00:01<00:01, 16.42it/s]
Testing lang zh-CN:  21%|████████████████▌                                                             | 10/47 [00:00<00:02, 16.52it/s]
Testing lang zh-CN:  89%|█████████████████████████████████████████████████████████████████████▋        | 42/47 [00:02<00:00, 16.53it/s]
Testing lang zh-TW:  51%|███████████████████████████████████████▊                                      | 24/47 [00:01<00:01, 16.52it/s]
Testing lang zh-TW: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
Testing lang zh-TW: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
{'af-ZA': {'precision_macro': 0.5983921947156483, 'precision_micro': 0.5934767989240081, 'recall_macro': 0.5317918437647737, 'recall_micro': 0.5934767989240081, 'f1_macro': 0.5300431848552788, 'f1_micro': 0.5934767989240081, 'accuracy': 0.5934767989240081}, 'am-ET': {'precision_macro': 0.5698864401783644, 'precision_micro': 0.30060524546065903, 'recall_macro': 0.2754429466604104, 'recall_micro': 0.30060524546065903, 'f1_macro': 0.3397583792249941, 'f1_micro': 0.30060524546065903, 'accuracy': 0.30060524546065903}, 'ar-SA': {'precision_macro': 0.6746543808523365, 'precision_micro': 0.47007397444519167, 'recall_macro': 0.44813183155722897, 'recall_micro': 0.47007397444519167, 'f1_macro': 0.5167491457554472, 'f1_micro': 0.47007397444519167, 'accuracy': 0.47007397444519167}, 'az-AZ': {'precision_macro': 0.6370988494579506, 'precision_micro': 0.5083221250840618, 'recall_macro': 0.4655053659548792, 'recall_micro': 0.5083221250840618, 'f1_macro': 0.5175528255933247, 'f1_micro': 0.5083221250840618, 'accuracy': 0.5083221250840618}, 'bn-BD': {'precision_macro': 0.6730093734356516, 'precision_micro': 0.5726294552790854, 'recall_macro': 0.5324870362187305, 'recall_micro': 0.5726294552790854, 'f1_macro': 0.577194959029392, 'f1_micro': 0.5726294552790854, 'accuracy': 0.5726294552790854}, 'ca-ES': {'precision_macro': 0.6781613707379925, 'precision_micro': 0.6021631921093925, 'recall_macro': 0.5615218739699908, 'recall_micro': 0.6021631921093925, 'f1_macro': 0.5985333412989196, 'f1_micro': 0.6021631921093925, 'accuracy': 0.6021631921093925}, 'cy-GB': {'precision_macro': 0.6281825080176479, 'precision_micro': 0.5520703237582861, 'recall_macro': 0.509529110082211, 'recall_micro': 0.5520703237582861, 'f1_macro': 0.5463935980862911, 'f1_micro': 0.5520703237582861, 'accuracy': 0.5520703237582861}, 'da-DK': {'precision_macro': 0.6355277646577939, 'precision_micro': 0.5761180228648285, 'recall_macro': 0.5275832034724154, 'recall_micro': 0.5761180228648285, 'f1_macro': 0.5621268455604886, 'f1_micro': 0.5761180228648285, 'accuracy': 0.5761180228648285}, 'de-DE': {'precision_macro': 0.6563193372750022, 'precision_micro': 0.6064036464170963, 'recall_macro': 0.560953129966748, 'recall_micro': 0.6064036464170963, 'f1_macro': 0.5910040143103708, 'f1_micro': 0.6064036464170963, 'accuracy': 0.6064036464170963}, 'el-GR': {'precision_macro': 0.670161374146927, 'precision_micro': 0.6301950235373235, 'recall_macro': 0.5856877963902, 'recall_micro': 0.6301950235373235, 'f1_macro': 0.6123693039176519, 'f1_micro': 0.6301950235373235, 'accuracy': 0.6301950235373235}, 'en-US': {'precision_macro': 0.6852901273610108, 'precision_micro': 0.6525952191722199, 'recall_macro': 0.6097946192446373, 'recall_micro': 0.6525952191722199, 'f1_macro': 0.6329497702266829, 'f1_micro': 0.6525952191722199, 'accuracy': 0.6525952191722199}, 'es-ES': {'precision_macro': 0.6965021967614751, 'precision_micro': 0.6701412239408204, 'recall_macro': 0.6287290996337889, 'recall_micro': 0.6701412239408204, 'f1_macro': 0.6488580544982838, 'f1_micro': 0.6701412239408204, 'accuracy': 0.6701412239408204}, 'fa-IR': {'precision_macro': 0.6849334552223153, 'precision_micro': 0.6637525218560861, 'recall_macro': 0.6193715771452984, 'recall_micro': 0.6637525218560861, 'f1_macro': 0.6383312860541437, 'f1_micro': 0.6637525218560861, 'accuracy': 0.6637525218560861}, 'fi-FI': {'precision_macro': 0.692824414333517, 'precision_micro': 0.6772264386588529, 'recall_macro': 0.6333368298269069, 'recall_micro': 0.6772264386588529, 'f1_macro': 0.6501477602439589, 'f1_micro': 0.6772264386588529, 'accuracy': 0.6772264386588529}, 'fr-FR': {'precision_macro': 0.7016150878942959, 'precision_micro': 0.6900022416498542, 'recall_macro': 0.6476727761966662, 'recall_micro': 0.6900022416498542, 'f1_macro': 0.6621103657762588, 'f1_micro': 0.6900022416498542, 'accuracy': 0.6900022416498542}, 'he-IL': {'precision_macro': 0.6883308681237357, 'precision_micro': 0.6784423335574983, 'recall_macro': 0.6333677525326028, 'recall_micro': 0.6784423335574983, 'f1_macro': 0.6477235259371076, 'f1_micro': 0.6784423335574983, 'accuracy': 0.6784423335574983}, 'hi-IN': {'precision_macro': 0.694082651081619, 'precision_micro': 0.6882194707069109, 'recall_macro': 0.6437011152842482, 'recall_micro': 0.6882194707069109, 'f1_macro': 0.6562623406730828, 'f1_micro': 0.6882194707069109, 'accuracy': 0.6882194707069109}, 'hu-HU': {'precision_macro': 0.6998142690302935, 'precision_micro': 0.6970410221923335, 'recall_macro': 0.6532161263756573, 'recall_micro': 0.6970410221923335, 'f1_macro': 0.664303263622237, 'f1_micro': 0.6970410221923335, 'accuracy': 0.6970410221923335}, 'hy-AM': {'precision_macro': 0.7045764721315926, 'precision_micro': 0.7046154390684175, 'recall_macro': 0.661420822028298, 'recall_micro': 0.7046154390684175, 'f1_macro': 0.6711010223410512, 'f1_micro': 0.7046154390684175, 'accuracy': 0.7046154390684175}, 'id-ID': {'precision_macro': 0.7099642961001794, 'precision_micro': 0.7124747814391392, 'recall_macro': 0.670043516076479, 'recall_micro': 0.7124747814391392, 'f1_macro': 0.6783913105946269, 'f1_micro': 0.7124747814391392, 'accuracy': 0.7124747814391392}, 'is-IS': {'precision_macro': 0.713875013298366, 'precision_micro': 0.7189771671950556, 'recall_macro': 0.6773462923250909, 'recall_micro': 0.7189771671950556, 'f1_macro': 0.6843299909524249, 'f1_micro': 0.7189771671950556, 'accuracy': 0.7189771671950556}, 'it-IT': {'precision_macro': 0.7121367647988593, 'precision_micro': 0.7195390352754173, 'recall_macro': 0.6768794461291979, 'recall_micro': 0.7195390352754173, 'f1_macro': 0.6831180643038058, 'f1_micro': 0.7195390352754173, 'accuracy': 0.7195390352754173}, 'ja-JP': {'precision_macro': 0.7160817910104396, 'precision_micro': 0.7255489605567089, 'recall_macro': 0.6831711913030513, 'recall_micro': 0.7255489605567089, 'f1_macro': 0.6885453257437235, 'f1_micro': 0.7255489605567089, 'accuracy': 0.7255489605567089}, 'jv-ID': {'precision_macro': 0.7186474597882816, 'precision_micro': 0.7300913472315624, 'recall_macro': 0.6880938591050205, 'recall_micro': 0.7300913472315624, 'f1_macro': 0.6924545465602631, 'f1_micro': 0.7300913472315625, 'accuracy': 0.7300913472315624}, 'ka-GE': {'precision_macro': 0.7194319277421807, 'precision_micro': 0.7324411566913248, 'recall_macro': 0.6905765889515075, 'recall_micro': 0.7324411566913248, 'f1_macro': 0.6943194991451004, 'f1_micro': 0.7324411566913248, 'accuracy': 0.7324411566913248}, 'km-KH': {'precision_macro': 0.711201882127747, 'precision_micro': 0.7057575914334488, 'recall_macro': 0.6656011093973845, 'recall_micro': 0.7057575914334488, 'f1_macro': 0.6742097345792322, 'f1_micro': 0.7057575914334488, 'accuracy': 0.7057575914334488}, 'kn-IN': {'precision_macro': 0.7009403836442272, 'precision_micro': 0.693192856609131, 'recall_macro': 0.6516357600061924, 'recall_micro': 0.693192856609131, 'f1_macro': 0.6617181714167695, 'f1_micro': 0.693192856609131, 'accuracy': 0.693192856609131}, 'ko-KR': {'precision_macro': 0.7044267646735821, 'precision_micro': 0.6989984628686713, 'recall_macro': 0.6572574972148897, 'recall_micro': 0.6989984628686713, 'f1_macro': 0.6666674301389776, 'f1_micro': 0.6989984628686713, 'accuracy': 0.6989984628686713}, 'lv-LV': {'precision_macro': 0.7081464671049856, 'precision_micro': 0.7043225193052431, 'recall_macro': 0.6632093808358275, 'recall_micro': 0.7043225193052431, 'f1_macro': 0.671847360465316, 'f1_micro': 0.7043225193052431, 'accuracy': 0.7043225193052431}, 'ml-IN': {'precision_macro': 0.699111770413833, 'precision_micro': 0.6912463573189868, 'recall_macro': 0.6486396329650136, 'recall_micro': 0.6912463573189868, 'f1_macro': 0.659533854975574, 'f1_micro': 0.6912463573189868, 'accuracy': 0.6912463573189868}, 'mn-MN': {'precision_macro': 0.6897641649918111, 'precision_micro': 0.6780810031021541, 'recall_macro': 0.6351598148690853, 'recall_micro': 0.6780810031021541, 'f1_macro': 0.6474773668361723, 'f1_micro': 0.6780810031021541, 'accuracy': 0.6780810031021541}, 'ms-MY': {'precision_macro': 0.6877052957042412, 'precision_micro': 0.6779169468728985, 'recall_macro': 0.6346292022300795, 'recall_micro': 0.6779169468728985, 'f1_macro': 0.646192724147331, 'f1_micro': 0.6779169468728985, 'accuracy': 0.6779169468728985}, 'my-MM': {'precision_macro': 0.6901868896600483, 'precision_micro': 0.6824702981394306, 'recall_macro': 0.6395214913319727, 'recall_micro': 0.6824702981394306, 'f1_macro': 0.650055128040139, 'f1_micro': 0.6824702981394306, 'accuracy': 0.6824702981394306}, 'nb-NO': {'precision_macro': 0.6887093651921489, 'precision_micro': 0.6835317852763163, 'recall_macro': 0.6396321584787236, 'recall_micro': 0.6835317852763163, 'f1_macro': 0.6495789006276579, 'f1_micro': 0.6835317852763163, 'accuracy': 0.6835317852763163}, 'nl-NL': {'precision_macro': 0.6889399206063794, 'precision_micro': 0.6855605725814199, 'recall_macro': 0.6404079178730232, 'recall_micro': 0.6855605725814199, 'f1_macro': 0.650374880391831, 'f1_micro': 0.6855605725814199, 'accuracy': 0.6855605725814199}, 'pl-PL': {'precision_macro': 0.6860002813939825, 'precision_micro': 0.6838526488829112, 'recall_macro': 0.6379013382952775, 'recall_micro': 0.6838526488829112, 'f1_macro': 0.6477840841852248, 'f1_micro': 0.6838526488829112, 'accuracy': 0.6838526488829112}, 'pt-PT': {'precision_macro': 0.6897755055283211, 'precision_micro': 0.6887984150929679, 'recall_macro': 0.6432448190324372, 'recall_micro': 0.6887984150929679, 'f1_macro': 0.6526739957476219, 'f1_micro': 0.6887984150929679, 'accuracy': 0.6887984150929679}, 'ro-RO': {'precision_macro': 0.6864744757613318, 'precision_micro': 0.6869270519944785, 'recall_macro': 0.6406620814692187, 'recall_micro': 0.6869270519944785, 'f1_macro': 0.6498162504529251, 'f1_micro': 0.6869270519944785, 'accuracy': 0.6869270519944785}, 'ru-RU': {'precision_macro': 0.6897481515630706, 'precision_micro': 0.6913679237149312, 'recall_macro': 0.6457788341532169, 'recall_micro': 0.6913679237149312, 'f1_macro': 0.6542792160791115, 'f1_micro': 0.6913679237149312, 'accuracy': 0.6913679237149312}, 'sl-SL': {'precision_macro': 0.6859242403881213, 'precision_micro': 0.6872982515131136, 'recall_macro': 0.6416649068594836, 'recall_micro': 0.6872982515131136, 'f1_macro': 0.6503523290423678, 'f1_micro': 0.6872982515131136, 'accuracy': 0.6872982515131136}, 'sq-AL': {'precision_macro': 0.6824637621985042, 'precision_micro': 0.6828858234782751, 'recall_macro': 0.6366309453021327, 'recall_micro': 0.6828858234782751, 'f1_macro': 0.646024577888328, 'f1_micro': 0.6828858234782751, 'accuracy': 0.6828858234782751}, 'sv-SE': {'precision_macro': 0.6807601367216288, 'precision_micro': 0.6821180388766132, 'recall_macro': 0.6354259609277313, 'recall_micro': 0.6821180388766132, 'f1_macro': 0.644463485355208, 'f1_micro': 0.6821180388766132, 'accuracy': 0.6821180388766132}, 'sw-KE': {'precision_macro': 0.6728717572205931, 'precision_micro': 0.6716817065732472, 'recall_macro': 0.6249362871936011, 'recall_micro': 0.6716817065732472, 'f1_macro': 0.6349972693628144, 'f1_micro': 0.6716817065732472, 'accuracy': 0.6716817065732472}, 'ta-IN': {'precision_macro': 0.6675938590976939, 'precision_micro': 0.6647918322430764, 'recall_macro': 0.6179237788485004, 'recall_micro': 0.6647918322430764, 'f1_macro': 0.6286678775078112, 'f1_micro': 0.6647918322430764, 'accuracy': 0.6647918322430764}, 'te-IN': {'precision_macro': 0.6621335537834715, 'precision_micro': 0.6582530075468879, 'recall_macro': 0.6108135100453591, 'recall_micro': 0.6582530075468879, 'f1_macro': 0.6221624984043829, 'f1_micro': 0.6582530075468879, 'accuracy': 0.6582530075468879}, 'th-TH': {'precision_macro': 0.6561276746421137, 'precision_micro': 0.6504341978304727, 'recall_macro': 0.6025075351732744, 'recall_micro': 0.6504341978304727, 'f1_macro': 0.6147740445573757, 'f1_micro': 0.6504341978304727, 'accuracy': 0.6504341978304727}, 'tl-PH': {'precision_macro': 0.6512322377858458, 'precision_micro': 0.6451301349282433, 'recall_macro': 0.5971329240077398, 'recall_micro': 0.6451301349282433, 'f1_macro': 0.6096131898239199, 'f1_micro': 0.6451301349282433, 'accuracy': 0.6451301349282433}, 'tr-TR': {'precision_macro': 0.6542138460509169, 'precision_micro': 0.6493289060748711, 'recall_macro': 0.6016811396971583, 'recall_micro': 0.6493289060748711, 'f1_macro': 0.6136325738497695, 'f1_micro': 0.6493289060748711, 'accuracy': 0.6493289060748711}, 'ur-PK': {'precision_macro': 0.6507985711018479, 'precision_micro': 0.6453755678465064, 'recall_macro': 0.5967776234770338, 'recall_micro': 0.6453755678465064, 'f1_macro': 0.6092434941343625, 'f1_micro': 0.6453755678465064, 'accuracy': 0.6453755678465064}, 'vi-VN': {'precision_macro': 0.6537288451480979, 'precision_micro': 0.6495090786819099, 'recall_macro': 0.600921649265626, 'recall_micro': 0.6495090786819099, 'f1_macro': 0.6130887730632951, 'f1_micro': 0.6495090786819099, 'accuracy': 0.6495090786819099}, 'zh-CN': {'precision_macro': 0.6567893774583907, 'precision_micro': 0.6535991666337012, 'recall_macro': 0.6052252906968855, 'recall_micro': 0.6535991666337012, 'f1_macro': 0.6170620159607295, 'f1_micro': 0.6535991666337012, 'accuracy': 0.6535991666337012}, 'zh-TW': {'precision_macro': 0.6594782998733906, 'precision_micro': 0.6571633645439967, 'recall_macro': 0.6093830925607181, 'recall_micro': 0.6571633645439967, 'f1_macro': 0.620666741778701, 'f1_micro': 0.6571633645439967, 'accuracy': 0.6571633645439967}}