
  0%|                                                                                                        | 0/22490 [00:00<?, ?it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale










  0%|▍                                                                                           | 100/22490 [00:23<1:16:06,  4.90it/s]










  1%|▊                                                                                           | 197/22490 [00:43<1:15:59,  4.89it/s]










  1%|█▏                                                                                          | 295/22490 [01:03<1:17:03,  4.80it/s]











  2%|█▋                                                                                          | 402/22490 [01:25<1:15:37,  4.87it/s]










  2%|██                                                                                          | 500/22490 [01:46<1:18:50,  4.65it/s]










  3%|██▍                                                                                         | 597/22490 [02:06<1:14:19,  4.91it/s]










  3%|██▊                                                                                         | 695/22490 [02:26<1:14:02,  4.91it/s]











  4%|███▎                                                                                        | 802/22490 [02:48<1:18:26,  4.61it/s]










  4%|███▋                                                                                        | 900/22490 [03:08<1:13:43,  4.88it/s]










  4%|████                                                                                        | 998/22490 [03:28<1:13:12,  4.89it/s]










  5%|████▍                                                                                      | 1095/22490 [03:48<1:12:58,  4.89it/s]











  5%|████▊                                                                                      | 1200/22490 [04:10<1:12:29,  4.90it/s]










  6%|█████▎                                                                                     | 1298/22490 [04:30<1:12:09,  4.89it/s]










  6%|█████▋                                                                                     | 1396/22490 [04:50<1:11:43,  4.90it/s]










  7%|██████▊                                                                                                | 1493/22490 [05:10<1:11:29,  4.90it/s]











  7%|███████▎                                                                                               | 1600/22490 [05:32<1:11:18,  4.88it/s]










  8%|███████▊                                                                                               | 1698/22490 [05:52<1:10:56,  4.89it/s]










  8%|████████▏                                                                                              | 1796/22490 [06:12<1:10:45,  4.87it/s]











  8%|████████▋                                                                                              | 1903/22490 [06:34<1:10:11,  4.89it/s]










  9%|█████████▏                                                                                             | 2000/22490 [06:54<1:09:46,  4.89it/s]










  9%|█████████▌                                                                                             | 2098/22490 [07:14<1:09:25,  4.90it/s]










 10%|██████████                                                                                             | 2195/22490 [07:34<1:08:47,  4.92it/s]





 10%|██████████▎                                                                                            | 2248/22490 [07:45<1:10:26,  4.79it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 10%|██████████▎                                                                                            | 2249/22490 [07:45<1:26:22,  3.91it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 10%|██████████▌                                                                                            | 2301/22490 [08:00<1:09:27,  4.84it/s]










 11%|██████████▉                                                                                            | 2395/22490 [08:20<1:08:47,  4.87it/s]











 11%|███████████▍                                                                                           | 2502/22490 [08:42<1:08:26,  4.87it/s]










 12%|███████████▉                                                                                           | 2599/22490 [09:02<1:08:00,  4.87it/s]










 12%|████████████▎                                                                                          | 2696/22490 [09:22<1:07:36,  4.88it/s]











 12%|████████████▊                                                                                          | 2803/22490 [09:44<1:07:24,  4.87it/s]










 13%|█████████████▎                                                                                         | 2900/22490 [10:04<1:07:23,  4.84it/s]










 13%|█████████████▋                                                                                         | 2997/22490 [10:25<1:07:02,  4.85it/s]











 14%|██████████████▏                                                                                        | 3103/22490 [10:47<1:06:50,  4.83it/s]










 14%|██████████████▋                                                                                        | 3200/22490 [11:07<1:06:13,  4.85it/s]










 15%|███████████████                                                                                        | 3295/22490 [11:26<1:05:55,  4.85it/s]











 15%|███████████████▌                                                                                       | 3401/22490 [11:48<1:05:31,  4.86it/s]










 16%|████████████████                                                                                       | 3498/22490 [12:08<1:05:15,  4.85it/s]










 16%|████████████████▍                                                                                      | 3595/22490 [12:29<1:04:55,  4.85it/s]











 16%|████████████████▉                                                                                      | 3701/22490 [12:51<1:04:45,  4.84it/s]










 17%|█████████████████▍                                                                                     | 3798/22490 [13:11<1:04:12,  4.85it/s]











 17%|█████████████████▉                                                                                     | 3905/22490 [13:33<1:03:51,  4.85it/s]










 18%|██████████████████▎                                                                                    | 4001/22490 [13:53<1:03:37,  4.84it/s]










 18%|██████████████████▊                                                                                    | 4098/22490 [14:13<1:03:12,  4.85it/s]











 19%|███████████████████▏                                                                                   | 4202/22490 [14:35<1:02:59,  4.84it/s]










 19%|███████████████████▋                                                                                   | 4299/22490 [14:55<1:02:38,  4.84it/s]










 20%|████████████████████▏                                                                                  | 4396/22490 [15:15<1:02:10,  4.85it/s]










 20%|████████████████████▌                                                                                  | 4497/22490 [15:36<1:01:25,  4.88it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 20%|████████████████████▌                                                                                  | 4498/22490 [15:36<1:13:40,  4.07it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 20%|████████████████████▌                                                                                  | 4499/22490 [15:41<8:02:27,  1.61s/it]










 20%|█████████████████████                                                                                  | 4597/22490 [16:01<1:01:00,  4.89it/s]











 21%|█████████████████████▌                                                                                 | 4704/22490 [16:23<1:00:45,  4.88it/s]










 21%|█████████████████████▉                                                                                 | 4801/22490 [16:43<1:00:57,  4.84it/s]










 22%|██████████████████████▍                                                                                | 4898/22490 [17:03<1:04:20,  4.56it/s]










 22%|██████████████████████▉                                                                                | 4995/22490 [17:23<1:08:07,  4.28it/s]











 23%|███████████████████████▎                                                                               | 5102/22490 [17:45<1:00:31,  4.79it/s]










 23%|███████████████████████▊                                                                               | 5199/22490 [18:05<1:03:19,  4.55it/s]










 24%|████████████████████████▋                                                                                | 5296/22490 [18:25<59:10,  4.84it/s]











 24%|████████████████████████▋                                                                              | 5400/22490 [18:47<1:10:00,  4.07it/s]










 24%|█████████████████████████▏                                                                             | 5497/22490 [19:07<1:09:10,  4.09it/s]










 25%|██████████████████████████                                                                               | 5594/22490 [19:27<57:59,  4.86it/s]











 25%|██████████████████████████▌                                                                              | 5700/22490 [19:49<57:39,  4.85it/s]










 26%|███████████████████████████                                                                              | 5798/22490 [20:09<57:08,  4.87it/s]










 26%|███████████████████████████▌                                                                             | 5894/22490 [20:29<56:53,  4.86it/s]











 27%|████████████████████████████                                                                             | 6001/22490 [20:51<56:28,  4.87it/s]










 27%|████████████████████████████▍                                                                            | 6098/22490 [21:11<56:12,  4.86it/s]










 28%|████████████████████████████▉                                                                            | 6195/22490 [21:32<55:58,  4.85it/s]











 28%|█████████████████████████████▍                                                                           | 6301/22490 [21:53<55:26,  4.87it/s]










 28%|█████████████████████████████▊                                                                           | 6398/22490 [22:14<55:05,  4.87it/s]










 29%|██████████████████████████████▎                                                                          | 6495/22490 [22:34<54:39,  4.88it/s]











 29%|██████████████████████████████▊                                                                          | 6602/22490 [22:56<54:15,  4.88it/s]










 30%|███████████████████████████████▎                                                                         | 6699/22490 [23:16<53:41,  4.90it/s]




 30%|███████████████████████████████▍                                                                         | 6746/22490 [23:26<53:33,  4.90it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 30%|██████████████████████████████▉                                                                        | 6747/22490 [23:26<1:05:46,  3.99it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 30%|███████████████████████████████▊                                                                         | 6802/22490 [23:42<53:30,  4.89it/s]










 31%|████████████████████████████████▏                                                                        | 6899/22490 [24:02<53:06,  4.89it/s]










 31%|████████████████████████████████▋                                                                        | 6996/22490 [24:22<52:56,  4.88it/s]











 32%|█████████████████████████████████▏                                                                       | 7103/22490 [24:44<52:40,  4.87it/s]










 32%|█████████████████████████████████▌                                                                       | 7198/22490 [25:04<52:15,  4.88it/s]










 32%|██████████████████████████████████                                                                       | 7295/22490 [25:24<52:08,  4.86it/s]











 33%|██████████████████████████████████▌                                                                      | 7402/22490 [25:46<51:30,  4.88it/s]










 33%|███████████████████████████████████                                                                      | 7499/22490 [26:06<51:15,  4.87it/s]










 34%|███████████████████████████████████▍                                                                     | 7596/22490 [26:26<51:01,  4.86it/s]











 34%|███████████████████████████████████▉                                                                     | 7703/22490 [26:48<50:48,  4.85it/s]










 35%|████████████████████████████████████▍                                                                    | 7800/22490 [27:08<50:26,  4.85it/s]










 35%|████████████████████████████████████▊                                                                    | 7897/22490 [27:28<50:06,  4.85it/s]











 36%|█████████████████████████████████████▎                                                                   | 8002/22490 [27:50<49:40,  4.86it/s]










 36%|█████████████████████████████████████▊                                                                   | 8099/22490 [28:10<49:23,  4.86it/s]










 36%|██████████████████████████████████████▎                                                                  | 8196/22490 [28:30<49:00,  4.86it/s]











 37%|██████████████████████████████████████▊                                                                  | 8303/22490 [28:52<48:41,  4.86it/s]










 37%|███████████████████████████████████████▏                                                                 | 8400/22490 [29:12<48:13,  4.87it/s]










 38%|███████████████████████████████████████▋                                                                 | 8497/22490 [29:32<47:58,  4.86it/s]











 38%|████████████████████████████████████████▏                                                                | 8604/22490 [29:54<47:35,  4.86it/s]










 39%|████████████████████████████████████████▌                                                                | 8701/22490 [30:14<47:18,  4.86it/s]










 39%|█████████████████████████████████████████                                                                | 8798/22490 [30:35<46:50,  4.87it/s]











 40%|█████████████████████████████████████████▌                                                               | 8905/22490 [30:57<46:37,  4.86it/s]









 40%|█████████████████████████████████████████▉                                                               | 8995/22490 [31:15<45:58,  4.89it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 40%|██████████████████████████████████████████                                                               | 8996/22490 [31:16<56:06,  4.01it/s]
 40%|██████████████████████████████████████████                                                               | 8996/22490 [31:16<56:06,  4.01it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale










 40%|██████████████████████████████████████████▍                                                              | 9102/22490 [31:42<45:59,  4.85it/s]










 41%|██████████████████████████████████████████▉                                                              | 9196/22490 [32:02<46:27,  4.77it/s]











 41%|███████████████████████████████████████████▍                                                             | 9299/22490 [32:24<45:26,  4.84it/s]










 42%|███████████████████████████████████████████▊                                                             | 9396/22490 [32:44<44:46,  4.87it/s]











 42%|████████████████████████████████████████████▎                                                            | 9503/22490 [33:07<44:39,  4.85it/s]










 43%|████████████████████████████████████████████▊                                                            | 9600/22490 [33:27<44:23,  4.84it/s]










 43%|█████████████████████████████████████████████▎                                                           | 9698/22490 [33:47<45:44,  4.66it/s]











 44%|█████████████████████████████████████████████▊                                                           | 9804/22490 [34:09<43:49,  4.82it/s]










 44%|██████████████████████████████████████████████▏                                                          | 9902/22490 [34:29<45:04,  4.65it/s]










 44%|██████████████████████████████████████████████▋                                                          | 9999/22490 [34:49<46:34,  4.47it/s]











 45%|██████████████████████████████████████████████▋                                                         | 10103/22490 [35:11<48:07,  4.29it/s]










 45%|███████████████████████████████████████████████▏                                                        | 10201/22490 [35:31<42:05,  4.87it/s]










 46%|███████████████████████████████████████████████▌                                                        | 10298/22490 [35:51<41:49,  4.86it/s]











 46%|████████████████████████████████████████████████                                                        | 10405/22490 [36:13<41:22,  4.87it/s]










 47%|████████████████████████████████████████████████▌                                                       | 10502/22490 [36:33<41:03,  4.87it/s]










 47%|█████████████████████████████████████████████████                                                       | 10599/22490 [36:53<40:39,  4.87it/s]











 48%|█████████████████████████████████████████████████▌                                                      | 10706/22490 [37:15<40:14,  4.88it/s]










 48%|█████████████████████████████████████████████████▉                                                      | 10804/22490 [37:35<40:00,  4.87it/s]










 48%|██████████████████████████████████████████████████▍                                                     | 10901/22490 [37:55<39:46,  4.86it/s]










 49%|██████████████████████████████████████████████████▊                                                     | 10995/22490 [38:15<39:18,  4.87it/s]











 49%|███████████████████████████████████████████████████▎                                                    | 11102/22490 [38:37<39:06,  4.85it/s]










 50%|███████████████████████████████████████████████████▊                                                    | 11200/22490 [38:57<38:23,  4.90it/s]




 50%|███████████████████████████████████████████████████▉                                                    | 11244/22490 [39:06<38:16,  4.90it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 50%|████████████████████████████████████████████████████                                                    | 11245/22490 [39:07<45:50,  4.09it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 50%|████████████████████████████████████████████████████▎                                                   | 11302/22490 [39:23<38:05,  4.90it/s]










 51%|████████████████████████████████████████████████████▋                                                   | 11400/22490 [39:43<37:57,  4.87it/s]











 51%|█████████████████████████████████████████████████████▏                                                  | 11505/22490 [40:05<37:41,  4.86it/s]










 52%|█████████████████████████████████████████████████████▋                                                  | 11603/22490 [40:25<37:02,  4.90it/s]










 52%|██████████████████████████████████████████████████████                                                  | 11701/22490 [40:45<36:40,  4.90it/s]










 52%|██████████████████████████████████████████████████████▌                                                 | 11799/22490 [41:06<36:22,  4.90it/s]











 53%|███████████████████████████████████████████████████████                                                 | 11906/22490 [41:27<35:54,  4.91it/s]










 53%|███████████████████████████████████████████████████████▌                                                | 12004/22490 [41:48<35:40,  4.90it/s]










 54%|███████████████████████████████████████████████████████▉                                                | 12102/22490 [42:08<35:31,  4.87it/s]










 54%|████████████████████████████████████████████████████████▍                                               | 12200/22490 [42:28<35:03,  4.89it/s]











 55%|████████████████████████████████████████████████████████▉                                               | 12305/22490 [42:49<34:44,  4.89it/s]










 55%|█████████████████████████████████████████████████████████▎                                              | 12403/22490 [43:09<34:14,  4.91it/s]










 56%|█████████████████████████████████████████████████████████▊                                              | 12501/22490 [43:29<34:01,  4.89it/s]










 56%|██████████████████████████████████████████████████████████▎                                             | 12599/22490 [43:50<33:35,  4.91it/s]











 57%|██████████████████████████████████████████████████████████▊                                             | 12707/22490 [44:12<33:10,  4.91it/s]










 57%|███████████████████████████████████████████████████████████▏                                            | 12804/22490 [44:32<32:56,  4.90it/s]










 57%|███████████████████████████████████████████████████████████▋                                            | 12902/22490 [44:52<32:45,  4.88it/s]










 58%|████████████████████████████████████████████████████████████                                            | 13000/22490 [45:12<32:27,  4.87it/s]










 58%|████████████████████████████████████████████████████████████▌                                           | 13097/22490 [45:32<32:01,  4.89it/s]











 59%|█████████████████████████████████████████████████████████████                                           | 13205/22490 [45:54<31:32,  4.91it/s]










 59%|█████████████████████████████████████████████████████████████▌                                          | 13302/22490 [46:14<31:21,  4.88it/s]











 60%|██████████████████████████████████████████████████████████████                                          | 13410/22490 [46:36<30:55,  4.89it/s]








 60%|██████████████████████████████████████████████████████████████▍                                         | 13493/22490 [46:53<30:28,  4.92it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 60%|██████████████████████████████████████████████████████████████▍                                         | 13494/22490 [46:54<36:39,  4.09it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale

 60%|██████████████████████████████████████████████████████████████▍                                         | 13505/22490 [47:00<36:24,  4.11it/s]










 60%|██████████████████████████████████████████████████████████████▉                                         | 13600/22490 [47:20<30:17,  4.89it/s]











 61%|███████████████████████████████████████████████████████████████▍                                        | 13707/22490 [47:42<30:00,  4.88it/s]










 61%|███████████████████████████████████████████████████████████████▊                                        | 13805/22490 [48:02<29:36,  4.89it/s]










 62%|████████████████████████████████████████████████████████████████▎                                       | 13903/22490 [48:22<29:14,  4.89it/s]










 62%|████████████████████████████████████████████████████████████████▋                                       | 14000/22490 [48:42<29:06,  4.86it/s]











 63%|█████████████████████████████████████████████████████████████████▏                                      | 14107/22490 [49:04<28:35,  4.89it/s]










 63%|█████████████████████████████████████████████████████████████████▋                                      | 14205/22490 [49:24<28:18,  4.88it/s]










 64%|██████████████████████████████████████████████████████████████████▏                                     | 14303/22490 [49:45<28:01,  4.87it/s]











 64%|██████████████████████████████████████████████████████████████████▋                                     | 14408/22490 [50:06<27:27,  4.90it/s]










 64%|███████████████████████████████████████████████████████████████████                                     | 14505/22490 [50:26<27:20,  4.87it/s]










 65%|███████████████████████████████████████████████████████████████████▌                                    | 14602/22490 [50:46<26:59,  4.87it/s]










 65%|███████████████████████████████████████████████████████████████████▉                                    | 14700/22490 [51:06<26:44,  4.85it/s]











 66%|████████████████████████████████████████████████████████████████████▍                                   | 14807/22490 [51:28<26:21,  4.86it/s]










 66%|████████████████████████████████████████████████████████████████████▉                                   | 14905/22490 [51:49<28:06,  4.50it/s]










 67%|█████████████████████████████████████████████████████████████████████▎                                  | 15002/22490 [52:09<29:50,  4.18it/s]











 67%|█████████████████████████████████████████████████████████████████████▊                                  | 15110/22490 [52:31<26:32,  4.63it/s]










 68%|██████████████████████████████████████████████████████████████████████▎                                 | 15205/22490 [52:50<24:48,  4.89it/s]










 68%|██████████████████████████████████████████████████████████████████████▊                                 | 15303/22490 [53:10<24:34,  4.87it/s]










 68%|███████████████████████████████████████████████████████████████████████▏                                | 15400/22490 [53:30<24:11,  4.89it/s]











 69%|███████████████████████████████████████████████████████████████████████▋                                | 15508/22490 [53:53<23:55,  4.87it/s]










 69%|████████████████████████████████████████████████████████████████████████▏                               | 15605/22490 [54:13<23:38,  4.86it/s]










 70%|████████████████████████████████████████████████████████████████████████▌                               | 15702/22490 [54:33<23:09,  4.89it/s]




 70%|████████████████████████████████████████████████████████████████████████▊                               | 15742/22490 [54:41<22:56,  4.90it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 70%|████████████████████████████████████████████████████████████████████████▊                               | 15743/22490 [54:41<27:59,  4.02it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale






 70%|█████████████████████████████████████████████████████████████████████████                               | 15807/22490 [54:59<22:48,  4.88it/s]










 71%|█████████████████████████████████████████████████████████████████████████▌                              | 15905/22490 [55:19<22:25,  4.89it/s]










 71%|█████████████████████████████████████████████████████████████████████████▉                              | 16000/22490 [55:39<22:09,  4.88it/s]











 72%|██████████████████████████████████████████████████████████████████████████▍                             | 16107/22490 [56:01<21:44,  4.89it/s]










 72%|██████████████████████████████████████████████████████████████████████████▉                             | 16205/22490 [56:21<21:29,  4.87it/s]










 72%|███████████████████████████████████████████████████████████████████████████▍                            | 16303/22490 [56:41<21:07,  4.88it/s]










 73%|███████████████████████████████████████████████████████████████████████████▊                            | 16400/22490 [57:01<20:43,  4.90it/s]











 73%|████████████████████████████████████████████████████████████████████████████▎                           | 16508/22490 [57:23<20:22,  4.89it/s]









 74%|████████████████████████████████████████████████████████████████████████████▋                           | 16596/22490 [57:41<20:02,  4.90it/s]










 74%|█████████████████████████████████████████████████████████████████████████████▏                          | 16693/22490 [58:01<19:44,  4.89it/s]










 75%|█████████████████████████████████████████████████████████████████████████████▋                          | 16791/22490 [58:21<19:31,  4.87it/s]











 75%|██████████████████████████████████████████████████████████████████████████████▏                         | 16896/22490 [58:43<19:02,  4.90it/s]










 76%|██████████████████████████████████████████████████████████████████████████████▌                         | 16994/22490 [59:03<18:41,  4.90it/s]










 76%|███████████████████████████████████████████████████████████████████████████████                         | 17092/22490 [59:23<18:21,  4.90it/s]











 76%|███████████████████████████████████████████████████████████████████████████████▌                        | 17199/22490 [59:45<18:01,  4.89it/s]










 77%|██████████████████████████████████████████████████████████████████████████████▍                       | 17297/22490 [1:00:05<17:41,  4.89it/s]










 77%|██████████████████████████████████████████████████████████████████████████████▉                       | 17395/22490 [1:00:25<17:18,  4.91it/s]










 78%|███████████████████████████████████████████████████████████████████████████████▎                      | 17493/22490 [1:00:45<16:58,  4.91it/s]










 78%|███████████████████████████████████████████████████████████████████████████████▊                      | 17591/22490 [1:01:06<16:41,  4.89it/s]











 79%|████████████████████████████████████████████████████████████████████████████████▎                     | 17696/22490 [1:01:27<16:20,  4.89it/s]










 79%|████████████████████████████████████████████████████████████████████████████████▋                     | 17794/22490 [1:01:47<15:58,  4.90it/s]










 80%|█████████████████████████████████████████████████████████████████████████████████▏                    | 17892/22490 [1:02:07<15:38,  4.90it/s]










 80%|█████████████████████████████████████████████████████████████████████████████████▌                    | 17991/22490 [1:02:28<15:14,  4.92it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 80%|█████████████████████████████████████████████████████████████████████████████████▌                    | 17992/22490 [1:02:28<18:24,  4.07it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 80%|█████████████████████████████████████████████████████████████████████████████████▌                    | 17996/22490 [1:02:33<50:37,  1.48it/s]










 80%|██████████████████████████████████████████████████████████████████████████████████                    | 18095/22490 [1:02:54<14:53,  4.92it/s]










 81%|██████████████████████████████████████████████████████████████████████████████████▌                   | 18193/22490 [1:03:14<14:35,  4.91it/s]











 81%|██████████████████████████████████████████████████████████████████████████████████▉                   | 18300/22490 [1:03:36<14:14,  4.91it/s]










 82%|███████████████████████████████████████████████████████████████████████████████████▍                  | 18398/22490 [1:03:56<13:55,  4.90it/s]










 82%|███████████████████████████████████████████████████████████████████████████████████▉                  | 18496/22490 [1:04:16<13:32,  4.91it/s]










 83%|████████████████████████████████████████████████████████████████████████████████████▎                 | 18592/22490 [1:04:36<13:15,  4.90it/s]










 83%|████████████████████████████████████████████████████████████████████████████████████▊                 | 18690/22490 [1:04:56<12:57,  4.89it/s]











 84%|█████████████████████████████████████████████████████████████████████████████████████▎                | 18797/22490 [1:05:18<12:32,  4.91it/s]










 84%|█████████████████████████████████████████████████████████████████████████████████████▋                | 18895/22490 [1:05:38<12:18,  4.87it/s]










 84%|██████████████████████████████████████████████████████████████████████████████████████▏               | 18994/22490 [1:05:58<12:06,  4.81it/s]










 85%|██████████████████████████████████████████████████████████████████████████████████████▌               | 19091/22490 [1:06:18<11:59,  4.72it/s]











 85%|███████████████████████████████████████████████████████████████████████████████████████               | 19199/22490 [1:06:40<11:20,  4.83it/s]










 86%|███████████████████████████████████████████████████████████████████████████████████████▌              | 19297/22490 [1:07:00<11:14,  4.74it/s]










 86%|███████████████████████████████████████████████████████████████████████████████████████▉              | 19393/22490 [1:07:20<10:32,  4.90it/s]










 87%|████████████████████████████████████████████████████████████████████████████████████████▍             | 19491/22490 [1:07:40<10:13,  4.89it/s]











 87%|████████████████████████████████████████████████████████████████████████████████████████▉             | 19598/22490 [1:08:02<09:50,  4.90it/s]










 88%|█████████████████████████████████████████████████████████████████████████████████████████▎            | 19696/22490 [1:08:22<09:31,  4.89it/s]










 88%|█████████████████████████████████████████████████████████████████████████████████████████▊            | 19794/22490 [1:08:42<09:11,  4.89it/s]










 88%|██████████████████████████████████████████████████████████████████████████████████████████▏           | 19892/22490 [1:09:02<08:49,  4.90it/s]











 89%|██████████████████████████████████████████████████████████████████████████████████████████▋           | 19999/22490 [1:09:24<08:28,  4.90it/s]










 89%|███████████████████████████████████████████████████████████████████████████████████████████▏          | 20097/22490 [1:09:44<08:08,  4.90it/s]










 90%|███████████████████████████████████████████████████████████████████████████████████████████▌          | 20192/22490 [1:10:04<07:47,  4.92it/s]




 90%|███████████████████████████████████████████████████████████████████████████████████████████▊          | 20240/22490 [1:10:14<07:37,  4.92it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 90%|███████████████████████████████████████████████████████████████████████████████████████████▊          | 20241/22490 [1:10:14<09:23,  3.99it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 402, 402])) that is different to the input size (torch.Size([128, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 90%|████████████████████████████████████████████████████████████████████████████████████████████          | 20298/22490 [1:10:30<07:25,  4.92it/s]










 91%|████████████████████████████████████████████████████████████████████████████████████████████▍         | 20395/22490 [1:10:50<07:08,  4.89it/s]










 91%|████████████████████████████████████████████████████████████████████████████████████████████▉         | 20493/22490 [1:11:10<06:49,  4.87it/s]











 92%|█████████████████████████████████████████████████████████████████████████████████████████████▍        | 20600/22490 [1:11:32<06:28,  4.86it/s]










 92%|█████████████████████████████████████████████████████████████████████████████████████████████▊        | 20697/22490 [1:11:52<06:06,  4.89it/s]










 92%|██████████████████████████████████████████████████████████████████████████████████████████████▎       | 20793/22490 [1:12:13<05:57,  4.74it/s]











 93%|██████████████████████████████████████████████████████████████████████████████████████████████▊       | 20898/22490 [1:12:35<05:28,  4.84it/s]











 93%|███████████████████████████████████████████████████████████████████████████████████████████████▎      | 21002/22490 [1:12:56<05:07,  4.84it/s]










 94%|███████████████████████████████████████████████████████████████████████████████████████████████▋      | 21098/22490 [1:13:16<04:46,  4.86it/s]










 94%|████████████████████████████████████████████████████████████████████████████████████████████████      | 21193/22490 [1:13:36<04:25,  4.88it/s]











 95%|████████████████████████████████████████████████████████████████████████████████████████████████▌     | 21301/22490 [1:13:59<04:03,  4.88it/s]










 95%|█████████████████████████████████████████████████████████████████████████████████████████████████     | 21396/22490 [1:14:19<03:45,  4.85it/s]











 96%|█████████████████████████████████████████████████████████████████████████████████████████████████▌    | 21503/22490 [1:14:41<03:24,  4.82it/s]










 96%|█████████████████████████████████████████████████████████████████████████████████████████████████▉    | 21599/22490 [1:15:01<03:03,  4.85it/s]









 96%|██████████████████████████████████████████████████████████████████████████████████████████████████▍   | 21696/22490 [1:15:21<02:44,  4.83it/s]











 97%|██████████████████████████████████████████████████████████████████████████████████████████████████▉   | 21802/22490 [1:15:43<02:21,  4.85it/s]










 97%|███████████████████████████████████████████████████████████████████████████████████████████████████▎  | 21896/22490 [1:16:02<02:02,  4.86it/s]










 98%|███████████████████████████████████████████████████████████████████████████████████████████████████▋  | 21993/22490 [1:16:23<01:42,  4.86it/s]











 98%|████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 22099/22490 [1:16:45<01:20,  4.86it/s]










 99%|████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 22196/22490 [1:17:05<01:00,  4.85it/s]











 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏| 22302/22490 [1:17:27<00:38,  4.85it/s]










100%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌| 22399/22490 [1:17:47<00:18,  4.86it/s]









100%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉| 22489/22490 [1:18:06<00:00,  4.89it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 402, 402])) that is different to the input size (torch.Size([106, 402, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 22490/22490 [1:18:06<00:00,  4.00it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 22490/22490 [1:18:10<00:00,  4.80it/s]

Testing lang af-ZA: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.28it/s]
Testing lang am-ET: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.65it/s]

Testing lang ar-SA: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.59it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang az-AZ: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang bn-BD: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.57it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang ca-ES: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang cy-GB: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang da-DK: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang de-DE: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.58it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang el-GR: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.67it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang en-US: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.67it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang es-ES: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.43it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang fa-IR: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.24it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang fi-FI: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.53it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang fr-FR: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.65it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang he-IL: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.55it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang hi-IN: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.65it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang hu-HU: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.66it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang hy-AM: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.54it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang id-ID: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.66it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang is-IS: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.56it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang ja-JP:  77%|████████████████████████████████████████████████████████████████████▉                     | 36/47 [00:02<00:00, 16.38it/s]
Testing lang jv-ID:  43%|██████████████████████████████████████▎                                                   | 20/47 [00:01<00:01, 16.49it/s]
Testing lang ka-GE:   9%|███████▋                                                                                   | 4/47 [00:00<00:02, 16.47it/s]
Testing lang ka-GE:  81%|████████████████████████████████████████████████████████████████████████▊                 | 38/47 [00:02<00:00, 16.49it/s]
Testing lang km-KH:  47%|██████████████████████████████████████████▏                                               | 22/47 [00:01<00:01, 16.40it/s]
Testing lang kn-IN:  13%|███████████▌                                                                               | 6/47 [00:00<00:02, 16.48it/s]
Testing lang kn-IN:  81%|████████████████████████████████████████████████████████████████████████▊                 | 38/47 [00:02<00:00, 16.50it/s]
Testing lang ko-KR:  51%|█████████████████████████████████████████████▉                                            | 24/47 [00:01<00:01, 16.50it/s]
Testing lang lv-LV:  17%|███████████████▍                                                                           | 8/47 [00:00<00:02, 16.33it/s]
Testing lang lv-LV:  85%|████████████████████████████████████████████████████████████████████████████▌             | 40/47 [00:02<00:00, 16.41it/s]
Testing lang ml-IN:  51%|█████████████████████████████████████████████▉                                            | 24/47 [00:01<00:01, 16.50it/s]
Testing lang mn-MN:  17%|███████████████▍                                                                           | 8/47 [00:00<00:02, 16.40it/s]
Testing lang mn-MN:  85%|████████████████████████████████████████████████████████████████████████████▌             | 40/47 [00:02<00:00, 16.43it/s]
Testing lang ms-MY:  51%|█████████████████████████████████████████████▉                                            | 24/47 [00:01<00:01, 16.43it/s]
Testing lang my-MM:  13%|███████████▌                                                                               | 6/47 [00:00<00:02, 16.48it/s]
Testing lang my-MM:  89%|████████████████████████████████████████████████████████████████████████████████▍         | 42/47 [00:02<00:00, 16.51it/s]
Testing lang nb-NO:  51%|█████████████████████████████████████████████▉                                            | 24/47 [00:01<00:01, 16.43it/s]
Testing lang nl-NL:  17%|███████████████▍                                                                           | 8/47 [00:00<00:02, 16.37it/s]
Testing lang nl-NL:  89%|████████████████████████████████████████████████████████████████████████████████▍         | 42/47 [00:02<00:00, 16.40it/s]
Testing lang pl-PL:  51%|█████████████████████████████████████████████▉                                            | 24/47 [00:01<00:01, 16.49it/s]
Testing lang pt-PT:  17%|███████████████▍                                                                           | 8/47 [00:00<00:02, 16.35it/s]
Testing lang pt-PT:  89%|████████████████████████████████████████████████████████████████████████████████▍         | 42/47 [00:02<00:00, 16.42it/s]
Testing lang ro-RO:  51%|█████████████████████████████████████████████▉                                            | 24/47 [00:01<00:01, 16.50it/s]
Testing lang ru-RU:   9%|███████▋                                                                                   | 4/47 [00:00<00:04,  8.83it/s]
Testing lang ru-RU:  81%|████████████████████████████████████████████████████████████████████████▊                 | 38/47 [00:02<00:00, 16.37it/s]
Testing lang sl-SL:  43%|██████████████████████████████████████▎                                                   | 20/47 [00:01<00:01, 16.41it/s]
Testing lang sq-AL:   9%|███████▋                                                                                   | 4/47 [00:00<00:02, 16.45it/s]
Testing lang sq-AL:  77%|████████████████████████████████████████████████████████████████████▉                     | 36/47 [00:02<00:00, 16.49it/s]
Testing lang sv-SE:  43%|██████████████████████████████████████▎                                                   | 20/47 [00:01<00:01, 16.34it/s]
Testing lang sw-KE:   4%|███▊                                                                                       | 2/47 [00:00<00:02, 16.41it/s]
Testing lang sw-KE:  77%|████████████████████████████████████████████████████████████████████▉                     | 36/47 [00:02<00:00, 16.40it/s]
Testing lang ta-IN:  21%|███████████████████▏                                                                      | 10/47 [00:00<00:02, 16.33it/s]
Testing lang ta-IN:  89%|████████████████████████████████████████████████████████████████████████████████▍         | 42/47 [00:02<00:00, 16.39it/s]
Testing lang te-IN:  55%|█████████████████████████████████████████████████▊                                        | 26/47 [00:01<00:01, 16.50it/s]
Testing lang th-TH:  17%|███████████████▍                                                                           | 8/47 [00:00<00:02, 16.48it/s]
Testing lang th-TH:  85%|████████████████████████████████████████████████████████████████████████████▌             | 40/47 [00:02<00:00, 16.49it/s]
Testing lang tl-PH:  51%|█████████████████████████████████████████████▉                                            | 24/47 [00:01<00:01, 16.51it/s]
Testing lang tr-TR:  13%|███████████▌                                                                               | 6/47 [00:00<00:02, 16.34it/s]
Testing lang tr-TR:  81%|████████████████████████████████████████████████████████████████████████▊                 | 38/47 [00:02<00:00, 16.41it/s]
Testing lang ur-PK:  47%|██████████████████████████████████████████▏                                               | 22/47 [00:01<00:01, 16.41it/s]
Testing lang vi-VN:   9%|███████▋                                                                                   | 4/47 [00:00<00:02, 16.25it/s]
Testing lang vi-VN:  60%|█████████████████████████████████████████████████████▌                                    | 28/47 [00:01<00:01, 11.37it/s]
Testing lang zh-CN:  21%|███████████████████▏                                                                      | 10/47 [00:00<00:02, 16.41it/s]
Testing lang zh-CN:  94%|████████████████████████████████████████████████████████████████████████████████████▎     | 44/47 [00:02<00:00, 16.42it/s]
Testing lang zh-TW:  55%|█████████████████████████████████████████████████▊                                        | 26/47 [00:01<00:01, 16.49it/s]
Testing lang zh-TW: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.65it/s]
Testing lang zh-TW: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.65it/s]
{'af-ZA': {'precision_macro': 0.582529171422117, 'precision_micro': 0.5944855413584398, 'recall_macro': 0.5344543135540542, 'recall_micro': 0.5944855413584398, 'f1_macro': 0.5357688744434368, 'f1_micro': 0.5944855413584398, 'accuracy': 0.5944855413584398}, 'am-ET': {'precision_macro': 0.5502692389920364, 'precision_micro': 0.3024546065904506, 'recall_macro': 0.2776482441142501, 'recall_micro': 0.3024546065904506, 'f1_macro': 0.34531266237372593, 'f1_micro': 0.3024546065904506, 'accuracy': 0.3024546065904506}, 'ar-SA': {'precision_macro': 0.6534921746714478, 'precision_micro': 0.4683927370544721, 'recall_macro': 0.4365482951149186, 'recall_micro': 0.4683927370544721, 'f1_macro': 0.5060941878990487, 'f1_micro': 0.4683927370544721, 'accuracy': 0.4683927370544721}, 'az-AZ': {'precision_macro': 0.6336213722358426, 'precision_micro': 0.5139542703429725, 'recall_macro': 0.4647139361186401, 'recall_micro': 0.5139542703429725, 'f1_macro': 0.5215689124305746, 'f1_micro': 0.5139542703429725, 'accuracy': 0.5139542703429725}, 'bn-BD': {'precision_macro': 0.6693499221788997, 'precision_micro': 0.5774714189643577, 'recall_macro': 0.5319010861389435, 'recall_micro': 0.5774714189643577, 'f1_macro': 0.5797090434682538, 'f1_micro': 0.5774714189643577, 'accuracy': 0.5774714189643577}, 'ca-ES': {'precision_macro': 0.6731399396504187, 'precision_micro': 0.6063662855861914, 'recall_macro': 0.5585200480917738, 'recall_micro': 0.6063662855861914, 'f1_macro': 0.5990917291417126, 'f1_micro': 0.6063662855861914, 'accuracy': 0.6063662855861914}, 'cy-GB': {'precision_macro': 0.6347379182806012, 'precision_micro': 0.5575943894706504, 'recall_macro': 0.5063902186634114, 'recall_micro': 0.5575943894706504, 'f1_macro': 0.5503481146160352, 'f1_micro': 0.5575943894706504, 'accuracy': 0.5575943894706504}, 'da-DK': {'precision_macro': 0.6421363297900488, 'precision_micro': 0.5812878278412912, 'recall_macro': 0.5259545703053738, 'recall_micro': 0.5812878278412912, 'f1_macro': 0.5666963036459738, 'f1_micro': 0.5812878278412912, 'accuracy': 0.5812878278412912}, 'de-DE': {'precision_macro': 0.6612663163871103, 'precision_micro': 0.6112231936038257, 'recall_macro': 0.5601678904924776, 'recall_micro': 0.6112231936038257, 'f1_macro': 0.5954803816382035, 'f1_micro': 0.6112231936038257, 'accuracy': 0.6112231936038257}, 'el-GR': {'precision_macro': 0.6753011814487345, 'precision_micro': 0.6349361129791526, 'recall_macro': 0.584482911425411, 'recall_micro': 0.6349361129791526, 'f1_macro': 0.6164544124140537, 'f1_micro': 0.6349361129791526, 'accuracy': 0.6349361129791526}, 'en-US': {'precision_macro': 0.6907322105371235, 'precision_micro': 0.6571498441034419, 'recall_macro': 0.6094807307767157, 'recall_micro': 0.6571498441034419, 'f1_macro': 0.6376462985305054, 'f1_micro': 0.6571498441034419, 'accuracy': 0.6571498441034419}, 'es-ES': {'precision_macro': 0.7007551509522358, 'precision_micro': 0.6744283792871554, 'recall_macro': 0.6287604759377137, 'recall_micro': 0.6744283792871554, 'f1_macro': 0.6531255973249727, 'f1_micro': 0.6744283792871554, 'accuracy': 0.6744283792871554}, 'fa-IR': {'precision_macro': 0.6891376733443384, 'precision_micro': 0.6691324815063887, 'recall_macro': 0.6187254812459622, 'recall_micro': 0.6691324815063887, 'f1_macro': 0.642161911958676, 'f1_micro': 0.6691324815063887, 'accuracy': 0.6691324815063887}, 'fi-FI': {'precision_macro': 0.6975477916546391, 'precision_micro': 0.6824863099241042, 'recall_macro': 0.6336611572257264, 'recall_micro': 0.6824863099241042, 'f1_macro': 0.6543336387711775, 'f1_micro': 0.6824863099241042, 'accuracy': 0.6824863099241042}, 'fr-FR': {'precision_macro': 0.705259992696077, 'precision_micro': 0.6948217888365837, 'recall_macro': 0.6464798480348394, 'recall_micro': 0.6948217888365837, 'f1_macro': 0.6653058413625944, 'f1_micro': 0.6948217888365837, 'accuracy': 0.6948217888365837}, 'he-IL': {'precision_macro': 0.6927795303331935, 'precision_micro': 0.6825193342299932, 'recall_macro': 0.6313873249895625, 'recall_micro': 0.6825193342299932, 'f1_macro': 0.6508116821575165, 'f1_micro': 0.6825193342299932, 'accuracy': 0.6825193342299932}, 'hi-IN': {'precision_macro': 0.698839983970278, 'precision_micro': 0.6925115708691009, 'recall_macro': 0.6430010357613072, 'recall_micro': 0.6925115708691009, 'f1_macro': 0.660088065791239, 'f1_micro': 0.6925115708691009, 'accuracy': 0.6925115708691009}, 'hu-HU': {'precision_macro': 0.7041481829193372, 'precision_micro': 0.7014682806545618, 'recall_macro': 0.6521062282972963, 'recall_micro': 0.7014682806545618, 'f1_macro': 0.6677303777670679, 'f1_micro': 0.7014682806545618, 'accuracy': 0.7014682806545618}, 'hy-AM': {'precision_macro': 0.7077381480164621, 'precision_micro': 0.7089866562842884, 'recall_macro': 0.6592304216685928, 'recall_micro': 0.7089866562842884, 'f1_macro': 0.6736404781349367, 'f1_micro': 0.7089866562842884, 'accuracy': 0.7089866562842884}, 'id-ID': {'precision_macro': 0.7121393183924928, 'precision_micro': 0.7161903160726295, 'recall_macro': 0.667528636267863, 'recall_micro': 0.7161903160726295, 'f1_macro': 0.6801482436638097, 'f1_micro': 0.7161903160726295, 'accuracy': 0.7161903160726295}, 'is-IS': {'precision_macro': 0.7158665044641309, 'precision_micro': 0.7222755948378006, 'recall_macro': 0.6749600388814953, 'recall_micro': 0.7222755948378006, 'f1_macro': 0.6858986716490543, 'f1_micro': 0.7222755948378006, 'accuracy': 0.7222755948378006}, 'it-IT': {'precision_macro': 0.7148217511016793, 'precision_micro': 0.722993213914532, 'recall_macro': 0.6745215165006777, 'recall_micro': 0.722993213914532, 'f1_macro': 0.6850471721114354, 'f1_micro': 0.722993213914532, 'accuracy': 0.722993213914532}, 'ja-JP': {'precision_macro': 0.7189345471355426, 'precision_micro': 0.7292623022718634, 'recall_macro': 0.6813232122336176, 'recall_micro': 0.7292623022718634, 'f1_macro': 0.6907401949534662, 'f1_micro': 0.7292623022718634, 'accuracy': 0.7292623022718634}, 'jv-ID': {'precision_macro': 0.7218649341211203, 'precision_micro': 0.7339161622954494, 'recall_macro': 0.6870319676081248, 'recall_micro': 0.7339161622954494, 'f1_macro': 0.6952076006442874, 'f1_micro': 0.7339161622954494, 'accuracy': 0.7339161622954494}, 'ka-GE': {'precision_macro': 0.7224496633520947, 'precision_micro': 0.7362071284465367, 'recall_macro': 0.6893494623796198, 'recall_micro': 0.7362071284465367, 'f1_macro': 0.6969085947393113, 'f1_micro': 0.7362071284465367, 'accuracy': 0.7362071284465367}, 'km-KH': {'precision_macro': 0.7173783784865531, 'precision_micro': 0.7100512130774403, 'recall_macro': 0.6643275278740519, 'recall_micro': 0.7100512130774403, 'f1_macro': 0.680509129048472, 'f1_micro': 0.7100512130774403, 'accuracy': 0.7100512130774403}, 'kn-IN': {'precision_macro': 0.7084972419422676, 'precision_micro': 0.6987222595830531, 'recall_macro': 0.6515208597853805, 'recall_micro': 0.6987222595830531, 'f1_macro': 0.6692928216970357, 'f1_micro': 0.6987222595830531, 'accuracy': 0.6987222595830531}, 'ko-KR': {'precision_macro': 0.7118432588545768, 'precision_micro': 0.7043183783264483, 'recall_macro': 0.6575807400764809, 'recall_micro': 0.7043183783264483, 'f1_macro': 0.6743147325784332, 'f1_micro': 0.7043183783264483, 'accuracy': 0.7043183783264483}, 'lv-LV': {'precision_macro': 0.7152006139966943, 'precision_micro': 0.7093662314774019, 'recall_macro': 0.6635840155161006, 'recall_micro': 0.7093662314774019, 'f1_macro': 0.6792252906443771, 'f1_micro': 0.709366231477402, 'accuracy': 0.7093662314774019}, 'ml-IN': {'precision_macro': 0.705262857357168, 'precision_micro': 0.6961891952477023, 'recall_macro': 0.6489511625258417, 'recall_micro': 0.6961891952477023, 'f1_macro': 0.6665276077670725, 'f1_micro': 0.6961891952477023, 'accuracy': 0.6961891952477023}, 'mn-MN': {'precision_macro': 0.6972304810071621, 'precision_micro': 0.6828969347246024, 'recall_macro': 0.6348899489504297, 'recall_micro': 0.6828969347246024, 'f1_macro': 0.654989904970975, 'f1_micro': 0.6828969347246024, 'accuracy': 0.6828969347246024}, 'ms-MY': {'precision_macro': 0.6953746709586588, 'precision_micro': 0.6829501513113652, 'recall_macro': 0.6349458941490078, 'recall_micro': 0.6829501513113652, 'f1_macro': 0.6540167126075853, 'f1_micro': 0.6829501513113652, 'accuracy': 0.6829501513113652}, 'my-MM': {'precision_macro': 0.6975753472561064, 'precision_micro': 0.6873102239611991, 'recall_macro': 0.6391315695196883, 'recall_micro': 0.6873102239611991, 'f1_macro': 0.6574860356980871, 'f1_micro': 0.6873102239611991, 'accuracy': 0.6873102239611991}, 'nb-NO': {'precision_macro': 0.6957702023212442, 'precision_micro': 0.6881304640215198, 'recall_macro': 0.639137084614455, 'recall_micro': 0.6881304640215198, 'f1_macro': 0.6567178918600346, 'f1_micro': 0.6881304640215198, 'accuracy': 0.6881304640215198}, 'nl-NL': {'precision_macro': 0.6952555028221034, 'precision_micro': 0.6896435776731674, 'recall_macro': 0.6395061006362839, 'recall_micro': 0.6896435776731674, 'f1_macro': 0.6568205181627079, 'f1_micro': 0.6896435776731674, 'accuracy': 0.6896435776731674}, 'pl-PL': {'precision_macro': 0.6920438180824103, 'precision_micro': 0.6885881342001046, 'recall_macro': 0.6374624304902824, 'recall_micro': 0.6885881342001046, 'f1_macro': 0.6542543190560735, 'f1_micro': 0.6885881342001046, 'accuracy': 0.6885881342001046}, 'pt-PT': {'precision_macro': 0.6953172547384199, 'precision_micro': 0.6934331776295461, 'recall_macro': 0.6428257965676686, 'recall_micro': 0.6934331776295461, 'f1_macro': 0.6587451453693612, 'f1_micro': 0.6934331776295461, 'accuracy': 0.6934331776295461}, 'ro-RO': {'precision_macro': 0.6923718016696646, 'precision_micro': 0.6916168194528015, 'recall_macro': 0.6407667181009428, 'recall_micro': 0.6916168194528015, 'f1_macro': 0.6562214583990987, 'f1_micro': 0.6916168194528015, 'accuracy': 0.6916168194528015}, 'ru-RU': {'precision_macro': 0.6954973016311625, 'precision_micro': 0.6961098753297812, 'recall_macro': 0.6458829179584796, 'recall_micro': 0.6961098753297812, 'f1_macro': 0.6605327287712766, 'f1_micro': 0.6961098753297812, 'accuracy': 0.6961098753297812}, 'sl-SL': {'precision_macro': 0.6916197383470399, 'precision_micro': 0.6924092131809011, 'recall_macro': 0.6421570817431096, 'recall_micro': 0.6924092131809011, 'f1_macro': 0.6566635129312967, 'f1_micro': 0.6924092131809011, 'accuracy': 0.6924092131809011}, 'sq-AL': {'precision_macro': 0.6873255003879191, 'precision_micro': 0.6875194777502583, 'recall_macro': 0.6368789041928399, 'recall_micro': 0.6875194777502583, 'f1_macro': 0.6517797985335095, 'f1_micro': 0.6875194777502583, 'accuracy': 0.6875194777502583}, 'sv-SE': {'precision_macro': 0.6859408837438615, 'precision_micro': 0.6868415153553015, 'recall_macro': 0.6359774610924381, 'recall_micro': 0.6868415153553015, 'f1_macro': 0.6504860796742397, 'f1_micro': 0.6868415153553015, 'accuracy': 0.6868415153553015}, 'sw-KE': {'precision_macro': 0.6780641237147379, 'precision_micro': 0.6763969909760561, 'recall_macro': 0.6257192913638089, 'recall_micro': 0.6763969909760561, 'f1_macro': 0.6411054407333091, 'f1_micro': 0.6763969909760561, 'accuracy': 0.6763969909760561}, 'ta-IN': {'precision_macro': 0.6737141368829889, 'precision_micro': 0.6702864217154735, 'recall_macro': 0.6194577138291912, 'recall_micro': 0.6702864217154735, 'f1_macro': 0.63554759710715, 'f1_micro': 0.6702864217154735, 'accuracy': 0.6702864217154735}, 'te-IN': {'precision_macro': 0.6687858580806373, 'precision_micro': 0.6642681013225734, 'recall_macro': 0.6127735557888552, 'recall_micro': 0.6642681013225734, 'f1_macro': 0.6293721007180398, 'f1_micro': 0.6642681013225734, 'accuracy': 0.6642681013225734}, 'th-TH': {'precision_macro': 0.6623953204960079, 'precision_micro': 0.6567205637262068, 'recall_macro': 0.604571692172035, 'recall_micro': 0.6567205637262068, 'f1_macro': 0.6218036271872402, 'f1_micro': 0.6567205637262068, 'accuracy': 0.6567205637262068}, 'tl-PH': {'precision_macro': 0.6580600571410127, 'precision_micro': 0.651454449198014, 'recall_macro': 0.5987525059775791, 'recall_micro': 0.651454449198014, 'f1_macro': 0.6165753308548422, 'f1_micro': 0.651454449198014, 'accuracy': 0.651454449198014}, 'tr-TR': {'precision_macro': 0.6612471085076141, 'precision_micro': 0.6556335462900695, 'recall_macro': 0.6034777651588498, 'recall_micro': 0.6556335462900695, 'f1_macro': 0.6207451684209498, 'f1_micro': 0.6556335462900695, 'accuracy': 0.6556335462900695}, 'ur-PK': {'precision_macro': 0.657844192471152, 'precision_micro': 0.6516544748363367, 'recall_macro': 0.5994958108323291, 'recall_micro': 0.6516544748363367, 'f1_macro': 0.6167233618219787, 'f1_micro': 0.6516544748363367, 'accuracy': 0.6516544748363367}, 'vi-VN': {'precision_macro': 0.6606738768707313, 'precision_micro': 0.6556489576328177, 'recall_macro': 0.6036728775680792, 'recall_micro': 0.6556489576328177, 'f1_macro': 0.6204812050576104, 'f1_micro': 0.6556489576328177, 'accuracy': 0.6556489576328177}, 'zh-CN': {'precision_macro': 0.6633893591478949, 'precision_micro': 0.65951316639635, 'recall_macro': 0.607697758602134, 'recall_micro': 0.65951316639635, 'f1_macro': 0.6240891788871265, 'f1_micro': 0.65951316639635, 'accuracy': 0.65951316639635}, 'zh-TW': {'precision_macro': 0.6657439637014311, 'precision_micro': 0.6628925042677565, 'recall_macro': 0.6115809272403478, 'recall_micro': 0.6628925042677565, 'f1_macro': 0.6273913562409169, 'f1_micro': 0.6628925042677565, 'accuracy': 0.6628925042677565}}