
  0%|                                                                                                        | 0/22490 [00:00<?, ?it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale










  0%|▍                                                                                           | 102/22490 [00:23<1:15:59,  4.91it/s]










  1%|▊                                                                                           | 200/22490 [00:43<1:15:41,  4.91it/s]










  1%|█▏                                                                                          | 299/22490 [01:03<1:18:20,  4.72it/s]










  2%|█▌                                                                                          | 397/22490 [01:23<1:23:19,  4.42it/s]










  2%|██                                                                                          | 496/22490 [01:44<1:14:36,  4.91it/s]











  3%|██▍                                                                                         | 603/22490 [02:06<1:22:52,  4.40it/s]










  3%|██▊                                                                                         | 702/22490 [02:26<1:14:05,  4.90it/s]










  4%|███▎                                                                                        | 799/22490 [02:46<1:13:45,  4.90it/s]










  4%|███▋                                                                                        | 897/22490 [03:06<1:13:29,  4.90it/s]











  4%|████                                                                                       | 1005/22490 [03:28<1:13:03,  4.90it/s]










  5%|████▍                                                                                      | 1101/22490 [03:48<1:12:53,  4.89it/s]










  5%|████▊                                                                                      | 1199/22490 [04:08<1:12:12,  4.91it/s]










  6%|█████▏                                                                                     | 1297/22490 [04:28<1:11:55,  4.91it/s]










  6%|█████▋                                                                                     | 1395/22490 [04:48<1:11:39,  4.91it/s]











  7%|██████                                                                                     | 1503/22490 [05:10<1:11:23,  4.90it/s]










  7%|██████▍                                                                                    | 1601/22490 [05:30<1:11:09,  4.89it/s]










  8%|██████▊                                                                                    | 1699/22490 [05:50<1:10:44,  4.90it/s]










  8%|███████▎                                                                                   | 1797/22490 [06:10<1:10:13,  4.91it/s]











  8%|███████▋                                                                                   | 1905/22490 [06:32<1:10:05,  4.89it/s]










  9%|████████                                                                                   | 2003/22490 [06:52<1:09:40,  4.90it/s]










  9%|████████▌                                                                                  | 2101/22490 [07:12<1:09:21,  4.90it/s]










 10%|████████▉                                                                                  | 2197/22490 [07:32<1:08:30,  4.94it/s]





 10%|█████████                                                                                  | 2248/22490 [07:42<1:08:15,  4.94it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 10%|█████████                                                                                  | 2249/22490 [07:43<1:25:50,  3.93it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 10%|█████████▎                                                                                 | 2302/22490 [07:58<1:08:25,  4.92it/s]










 11%|█████████▋                                                                                 | 2400/22490 [08:18<1:08:00,  4.92it/s]










 11%|██████████                                                                                 | 2498/22490 [08:38<1:07:34,  4.93it/s]










 12%|██████████▌                                                                                | 2597/22490 [08:58<1:07:35,  4.91it/s]










 12%|██████████▉                                                                                | 2695/22490 [09:18<1:07:16,  4.90it/s]











 12%|███████████▎                                                                               | 2803/22490 [09:40<1:06:37,  4.92it/s]










 13%|███████████▋                                                                               | 2901/22490 [10:01<1:06:39,  4.90it/s]










 13%|████████████▏                                                                              | 2999/22490 [10:21<1:06:05,  4.92it/s]










 14%|████████████▌                                                                              | 3094/22490 [10:40<1:05:44,  4.92it/s]











 14%|████████████▉                                                                              | 3202/22490 [11:02<1:05:35,  4.90it/s]










 15%|█████████████▎                                                                             | 3300/22490 [11:22<1:05:22,  4.89it/s]










 15%|█████████████▋                                                                             | 3398/22490 [11:42<1:05:00,  4.89it/s]










 16%|██████████████▏                                                                            | 3496/22490 [12:02<1:04:34,  4.90it/s]











 16%|██████████████▌                                                                            | 3604/22490 [12:25<1:04:14,  4.90it/s]










 16%|██████████████▉                                                                            | 3702/22490 [12:45<1:03:48,  4.91it/s]










 17%|███████████████▍                                                                           | 3800/22490 [13:05<1:04:33,  4.82it/s]










 17%|███████████████▊                                                                           | 3898/22490 [13:25<1:06:55,  4.63it/s]











 18%|████████████████▏                                                                          | 4006/22490 [13:47<1:03:15,  4.87it/s]










 18%|████████████████▌                                                                          | 4101/22490 [14:06<1:04:31,  4.75it/s]










 19%|████████████████▉                                                                          | 4200/22490 [14:27<1:02:15,  4.90it/s]










 19%|█████████████████▍                                                                         | 4298/22490 [14:47<1:01:48,  4.91it/s]











 20%|█████████████████▊                                                                         | 4406/22490 [15:09<1:01:26,  4.91it/s]









 20%|██████████████████▏                                                                        | 4497/22490 [15:27<1:00:40,  4.94it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 20%|██████████████████▏                                                                        | 4498/22490 [15:28<1:13:58,  4.05it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 20%|██████████████████▏                                                                        | 4500/22490 [15:33<5:58:25,  1.20s/it]











 20%|██████████████████▋                                                                        | 4606/22490 [15:55<1:05:40,  4.54it/s]










 21%|███████████████████                                                                        | 4703/22490 [16:15<1:01:26,  4.82it/s]










 21%|███████████████████▍                                                                       | 4800/22490 [16:35<1:00:26,  4.88it/s]











 22%|███████████████████▊                                                                       | 4904/22490 [16:57<1:00:32,  4.84it/s]










 22%|████████████████████▋                                                                        | 5000/22490 [17:17<59:56,  4.86it/s]











 23%|████████████████████▋                                                                      | 5106/22490 [17:39<1:00:10,  4.81it/s]










 23%|█████████████████████▌                                                                       | 5203/22490 [17:59<59:29,  4.84it/s]










 24%|█████████████████████▉                                                                       | 5299/22490 [18:19<59:08,  4.85it/s]











 24%|██████████████████████▎                                                                      | 5405/22490 [18:41<58:38,  4.86it/s]










 24%|██████████████████████▊                                                                      | 5502/22490 [19:01<58:41,  4.82it/s]










 25%|███████████████████████▏                                                                     | 5598/22490 [19:21<58:21,  4.82it/s]











 25%|███████████████████████▌                                                                     | 5704/22490 [19:43<57:47,  4.84it/s]










 26%|███████████████████████▉                                                                     | 5801/22490 [20:04<57:50,  4.81it/s]











 26%|████████████████████████▍                                                                    | 5904/22490 [20:25<57:18,  4.82it/s]










 27%|████████████████████████▊                                                                    | 6000/22490 [20:45<56:59,  4.82it/s]










 27%|█████████████████████████▏                                                                   | 6097/22490 [21:05<56:43,  4.82it/s]











 28%|█████████████████████████▋                                                                   | 6203/22490 [21:27<56:20,  4.82it/s]










 28%|██████████████████████████                                                                   | 6299/22490 [21:47<56:00,  4.82it/s]











 28%|██████████████████████████▍                                                                  | 6405/22490 [22:10<55:40,  4.81it/s]










 29%|██████████████████████████▉                                                                  | 6501/22490 [22:30<55:32,  4.80it/s]











 29%|███████████████████████████▎                                                                 | 6608/22490 [22:52<54:52,  4.82it/s]










 30%|███████████████████████████▋                                                                 | 6704/22490 [23:12<53:44,  4.90it/s]




 30%|███████████████████████████▉                                                                 | 6746/22490 [23:20<53:25,  4.91it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 30%|███████████████████████████▎                                                               | 6747/22490 [23:21<1:05:55,  3.98it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 30%|████████████████████████████                                                                 | 6797/22490 [23:36<53:33,  4.88it/s]











 31%|████████████████████████████▌                                                                | 6903/22490 [23:58<53:42,  4.84it/s]










 31%|████████████████████████████▉                                                                | 6999/22490 [24:18<53:05,  4.86it/s]











 32%|█████████████████████████████▍                                                               | 7106/22490 [24:40<52:20,  4.90it/s]










 32%|█████████████████████████████▊                                                               | 7204/22490 [25:00<52:12,  4.88it/s]










 32%|██████████████████████████████▏                                                              | 7301/22490 [25:20<52:39,  4.81it/s]











 33%|██████████████████████████████▋                                                              | 7408/22490 [25:42<51:32,  4.88it/s]










 33%|███████████████████████████████                                                              | 7505/22490 [26:02<51:12,  4.88it/s]










 34%|███████████████████████████████▍                                                             | 7603/22490 [26:22<50:49,  4.88it/s]










 34%|███████████████████████████████▊                                                             | 7698/22490 [26:42<50:30,  4.88it/s]











 35%|████████████████████████████████▎                                                            | 7805/22490 [27:04<50:10,  4.88it/s]










 35%|████████████████████████████████▋                                                            | 7902/22490 [27:24<49:56,  4.87it/s]










 36%|█████████████████████████████████                                                            | 7999/22490 [27:44<49:25,  4.89it/s]











 36%|█████████████████████████████████▌                                                           | 8106/22490 [28:06<49:08,  4.88it/s]










 36%|█████████████████████████████████▉                                                           | 8203/22490 [28:26<48:56,  4.87it/s]










 37%|██████████████████████████████████▎                                                          | 8301/22490 [28:46<48:38,  4.86it/s]











 37%|██████████████████████████████████▊                                                          | 8408/22490 [29:08<48:14,  4.87it/s]










 38%|███████████████████████████████████▏                                                         | 8504/22490 [29:28<48:24,  4.82it/s]










 38%|███████████████████████████████████▌                                                         | 8599/22490 [29:48<47:37,  4.86it/s]











 39%|████████████████████████████████████                                                         | 8706/22490 [30:10<47:01,  4.88it/s]










 39%|████████████████████████████████████▍                                                        | 8803/22490 [30:30<46:55,  4.86it/s]










 40%|████████████████████████████████████▊                                                        | 8900/22490 [30:50<46:31,  4.87it/s]









 40%|█████████████████████████████████████▏                                                       | 8995/22490 [31:10<46:45,  4.81it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 40%|█████████████████████████████████████▏                                                       | 8996/22490 [31:10<55:48,  4.03it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 40%|████████████████████████████████████▍                                                      | 9003/22490 [31:16<1:23:43,  2.68it/s]










 40%|█████████████████████████████████████▋                                                       | 9101/22490 [31:36<45:25,  4.91it/s]










 41%|██████████████████████████████████████                                                       | 9199/22490 [31:56<45:05,  4.91it/s]











 41%|██████████████████████████████████████▍                                                      | 9307/22490 [32:19<44:52,  4.90it/s]










 42%|██████████████████████████████████████▉                                                      | 9405/22490 [32:39<44:37,  4.89it/s]










 42%|███████████████████████████████████████▎                                                     | 9503/22490 [32:59<44:23,  4.88it/s]










 43%|███████████████████████████████████████▋                                                     | 9598/22490 [33:18<45:58,  4.67it/s]











 43%|████████████████████████████████████████▏                                                    | 9706/22490 [33:40<44:10,  4.82it/s]










 44%|████████████████████████████████████████▌                                                    | 9804/22490 [34:01<45:51,  4.61it/s]










 44%|████████████████████████████████████████▉                                                    | 9901/22490 [34:21<48:23,  4.34it/s]










 44%|█████████████████████████████████████████▎                                                   | 9999/22490 [34:41<42:37,  4.88it/s]











 45%|█████████████████████████████████████████▎                                                  | 10106/22490 [35:03<42:08,  4.90it/s]










 45%|█████████████████████████████████████████▋                                                  | 10204/22490 [35:23<41:57,  4.88it/s]










 46%|██████████████████████████████████████████▏                                                 | 10302/22490 [35:43<41:34,  4.89it/s]










 46%|██████████████████████████████████████████▌                                                 | 10400/22490 [36:03<41:15,  4.88it/s]











 47%|██████████████████████████████████████████▉                                                 | 10505/22490 [36:25<40:48,  4.90it/s]










 47%|███████████████████████████████████████████▎                                                | 10602/22490 [36:45<40:29,  4.89it/s]










 48%|███████████████████████████████████████████▊                                                | 10700/22490 [37:05<40:01,  4.91it/s]











 48%|████████████████████████████████████████████▏                                               | 10807/22490 [37:27<39:49,  4.89it/s]










 48%|████████████████████████████████████████████▌                                               | 10905/22490 [37:47<39:33,  4.88it/s]









 49%|████████████████████████████████████████████▉                                               | 10993/22490 [38:05<39:17,  4.88it/s]










 49%|█████████████████████████████████████████████▎                                              | 11090/22490 [38:25<38:51,  4.89it/s]











 50%|█████████████████████████████████████████████▊                                              | 11197/22490 [38:47<38:12,  4.93it/s]




 50%|█████████████████████████████████████████████▉                                              | 11244/22490 [38:57<38:06,  4.92it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 50%|██████████████████████████████████████████████                                              | 11245/22490 [38:57<45:49,  4.09it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale




 50%|██████████████████████████████████████████████▏                                             | 11292/22490 [39:11<38:02,  4.91it/s]











 51%|██████████████████████████████████████████████▌                                             | 11397/22490 [39:33<37:53,  4.88it/s]










 51%|███████████████████████████████████████████████                                             | 11495/22490 [39:53<37:36,  4.87it/s]










 52%|███████████████████████████████████████████████▍                                            | 11592/22490 [40:13<37:31,  4.84it/s]










 52%|███████████████████████████████████████████████▊                                            | 11690/22490 [40:33<36:41,  4.91it/s]











 52%|████████████████████████████████████████████████▎                                           | 11797/22490 [40:55<36:23,  4.90it/s]










 53%|████████████████████████████████████████████████▋                                           | 11894/22490 [41:15<36:05,  4.89it/s]










 53%|█████████████████████████████████████████████████                                           | 11991/22490 [41:35<35:52,  4.88it/s]











 54%|█████████████████████████████████████████████████▍                                          | 12099/22490 [41:58<35:37,  4.86it/s]










 54%|█████████████████████████████████████████████████▉                                          | 12196/22490 [42:18<35:16,  4.86it/s]










 55%|██████████████████████████████████████████████████▎                                         | 12293/22490 [42:38<34:58,  4.86it/s]











 55%|██████████████████████████████████████████████████▋                                         | 12398/22490 [42:59<34:36,  4.86it/s]










 56%|███████████████████████████████████████████████████                                         | 12495/22490 [43:19<34:10,  4.88it/s]










 56%|███████████████████████████████████████████████████▌                                        | 12592/22490 [43:39<33:42,  4.89it/s]










 56%|███████████████████████████████████████████████████▉                                        | 12690/22490 [44:00<33:19,  4.90it/s]











 57%|████████████████████████████████████████████████████▎                                       | 12797/22490 [44:22<33:00,  4.90it/s]










 57%|████████████████████████████████████████████████████▋                                       | 12894/22490 [44:42<32:51,  4.87it/s]










 58%|█████████████████████████████████████████████████████▏                                      | 12992/22490 [45:02<32:46,  4.83it/s]











 58%|█████████████████████████████████████████████████████▌                                      | 13098/22490 [45:24<32:17,  4.85it/s]










 59%|█████████████████████████████████████████████████████▉                                      | 13196/22490 [45:44<31:51,  4.86it/s]










 59%|██████████████████████████████████████████████████████▎                                     | 13290/22490 [46:04<33:25,  4.59it/s]











 60%|██████████████████████████████████████████████████████▊                                     | 13397/22490 [46:26<31:31,  4.81it/s]









 60%|███████████████████████████████████████████████████████▏                                    | 13493/22490 [46:45<30:24,  4.93it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 60%|███████████████████████████████████████████████████████▏                                    | 13494/22490 [46:46<36:46,  4.08it/s]
 60%|███████████████████████████████████████████████████████▏                                    | 13494/22490 [46:46<36:46,  4.08it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale









 60%|███████████████████████████████████████████████████████▌                                    | 13590/22490 [47:10<37:08,  3.99it/s]











 61%|████████████████████████████████████████████████████████                                    | 13698/22490 [47:32<30:28,  4.81it/s]










 61%|████████████████████████████████████████████████████████▍                                   | 13797/22490 [47:52<29:26,  4.92it/s]










 62%|████████████████████████████████████████████████████████▊                                   | 13895/22490 [48:12<29:09,  4.91it/s]











 62%|█████████████████████████████████████████████████████████▎                                  | 14002/22490 [48:34<28:52,  4.90it/s]










 63%|█████████████████████████████████████████████████████████▋                                  | 14101/22490 [48:54<28:33,  4.90it/s]










 63%|██████████████████████████████████████████████████████████                                  | 14196/22490 [49:14<28:11,  4.90it/s]










 64%|██████████████████████████████████████████████████████████▍                                 | 14294/22490 [49:34<27:51,  4.90it/s]










 64%|██████████████████████████████████████████████████████████▊                                 | 14392/22490 [49:54<27:32,  4.90it/s]











 64%|███████████████████████████████████████████████████████████▎                                | 14500/22490 [50:16<27:06,  4.91it/s]










 65%|███████████████████████████████████████████████████████████▋                                | 14598/22490 [50:36<26:44,  4.92it/s]










 65%|████████████████████████████████████████████████████████████                                | 14696/22490 [50:56<26:28,  4.91it/s]










 66%|████████████████████████████████████████████████████████████▌                               | 14794/22490 [51:16<26:14,  4.89it/s]











 66%|████████████████████████████████████████████████████████████▉                               | 14902/22490 [51:39<25:54,  4.88it/s]










 67%|█████████████████████████████████████████████████████████████▎                              | 15000/22490 [51:59<25:25,  4.91it/s]










 67%|█████████████████████████████████████████████████████████████▋                              | 15095/22490 [52:18<25:14,  4.88it/s]










 68%|██████████████████████████████████████████████████████████████▏                             | 15193/22490 [52:38<24:50,  4.90it/s]











 68%|██████████████████████████████████████████████████████████████▌                             | 15300/22490 [53:00<24:28,  4.90it/s]










 68%|██████████████████████████████████████████████████████████████▉                             | 15398/22490 [53:20<24:07,  4.90it/s]










 69%|███████████████████████████████████████████████████████████████▍                            | 15496/22490 [53:41<23:46,  4.90it/s]










 69%|███████████████████████████████████████████████████████████████▊                            | 15593/22490 [54:01<23:30,  4.89it/s]











 70%|████████████████████████████████████████████████████████████████▏                           | 15701/22490 [54:23<23:02,  4.91it/s]




 70%|████████████████████████████████████████████████████████████████▍                           | 15742/22490 [54:31<23:05,  4.87it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 70%|████████████████████████████████████████████████████████████████▍                           | 15743/22490 [54:32<28:25,  3.96it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale





 70%|████████████████████████████████████████████████████████████████▌                           | 15795/22490 [54:47<22:55,  4.87it/s]











 71%|█████████████████████████████████████████████████████████████████                           | 15903/22490 [55:09<22:28,  4.89it/s]










 71%|█████████████████████████████████████████████████████████████████▍                          | 15998/22490 [55:29<22:09,  4.88it/s]










 72%|█████████████████████████████████████████████████████████████████▊                          | 16096/22490 [55:49<21:45,  4.90it/s]










 72%|██████████████████████████████████████████████████████████████████▏                         | 16193/22490 [56:09<21:23,  4.91it/s]











 72%|██████████████████████████████████████████████████████████████████▋                         | 16301/22490 [56:31<21:04,  4.89it/s]










 73%|███████████████████████████████████████████████████████████████████                         | 16399/22490 [56:51<20:40,  4.91it/s]










 73%|███████████████████████████████████████████████████████████████████▍                        | 16496/22490 [57:11<20:26,  4.89it/s]










 74%|███████████████████████████████████████████████████████████████████▉                        | 16594/22490 [57:31<20:08,  4.88it/s]











 74%|████████████████████████████████████████████████████████████████████▎                       | 16702/22490 [57:53<19:51,  4.86it/s]










 75%|████████████████████████████████████████████████████████████████████▋                       | 16799/22490 [58:13<19:31,  4.86it/s]










 75%|█████████████████████████████████████████████████████████████████████                       | 16895/22490 [58:33<19:05,  4.88it/s]











 76%|█████████████████████████████████████████████████████████████████████▌                      | 17002/22490 [58:55<18:51,  4.85it/s]










 76%|█████████████████████████████████████████████████████████████████████▉                      | 17100/22490 [59:15<18:23,  4.89it/s]










 76%|██████████████████████████████████████████████████████████████████████▎                     | 17197/22490 [59:35<17:58,  4.91it/s]










 77%|██████████████████████████████████████████████████████████████████████▋                     | 17295/22490 [59:55<17:40,  4.90it/s]











 77%|█████████████████████████████████████████████████████████████████████▋                    | 17402/22490 [1:00:17<17:20,  4.89it/s]










 78%|██████████████████████████████████████████████████████████████████████                    | 17500/22490 [1:00:37<16:56,  4.91it/s]










 78%|██████████████████████████████████████████████████████████████████████▍                   | 17598/22490 [1:00:58<16:45,  4.86it/s]










 79%|██████████████████████████████████████████████████████████████████████▊                   | 17695/22490 [1:01:17<16:20,  4.89it/s]











 79%|███████████████████████████████████████████████████████████████████████▏                  | 17800/22490 [1:01:39<16:03,  4.87it/s]










 80%|███████████████████████████████████████████████████████████████████████▌                  | 17898/22490 [1:01:59<15:40,  4.88it/s]









 80%|███████████████████████████████████████████████████████████████████████▉                  | 17991/22490 [1:02:18<15:18,  4.90it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 80%|████████████████████████████████████████████████████████████████████████                  | 17992/22490 [1:02:19<18:34,  4.04it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 80%|████████████████████████████████████████████████████████████████████████                  | 18002/22490 [1:02:25<19:24,  3.85it/s]










 80%|████████████████████████████████████████████████████████████████████████▍                 | 18100/22490 [1:02:45<14:50,  4.93it/s]










 81%|████████████████████████████████████████████████████████████████████████▊                 | 18198/22490 [1:03:05<14:34,  4.91it/s]










 81%|█████████████████████████████████████████████████████████████████████████▏                | 18296/22490 [1:03:26<14:14,  4.91it/s]










 82%|█████████████████████████████████████████████████████████████████████████▌                | 18394/22490 [1:03:46<13:53,  4.91it/s]











 82%|██████████████████████████████████████████████████████████████████████████                | 18502/22490 [1:04:08<13:36,  4.88it/s]










 83%|██████████████████████████████████████████████████████████████████████████▍               | 18600/22490 [1:04:28<13:13,  4.90it/s]










 83%|██████████████████████████████████████████████████████████████████████████▊               | 18695/22490 [1:04:47<12:55,  4.89it/s]










 84%|███████████████████████████████████████████████████████████████████████████▏              | 18793/22490 [1:05:07<12:56,  4.76it/s]











 84%|███████████████████████████████████████████████████████████████████████████▋              | 18901/22490 [1:05:30<12:23,  4.83it/s]










 84%|████████████████████████████████████████████████████████████████████████████              | 18999/22490 [1:05:50<12:04,  4.82it/s]










 85%|████████████████████████████████████████████████████████████████████████████▍             | 19097/22490 [1:06:10<13:30,  4.19it/s]










 85%|████████████████████████████████████████████████████████████████████████████▊             | 19195/22490 [1:06:30<11:13,  4.89it/s]











 86%|█████████████████████████████████████████████████████████████████████████████▏            | 19302/22490 [1:06:52<10:53,  4.88it/s]










 86%|█████████████████████████████████████████████████████████████████████████████▋            | 19400/22490 [1:07:12<10:31,  4.89it/s]










 87%|██████████████████████████████████████████████████████████████████████████████            | 19498/22490 [1:07:32<10:12,  4.88it/s]










 87%|██████████████████████████████████████████████████████████████████████████████▍           | 19593/22490 [1:07:52<09:52,  4.89it/s]











 88%|██████████████████████████████████████████████████████████████████████████████▊           | 19701/22490 [1:08:14<09:32,  4.87it/s]










 88%|███████████████████████████████████████████████████████████████████████████████▏          | 19799/22490 [1:08:34<09:10,  4.89it/s]










 88%|███████████████████████████████████████████████████████████████████████████████▌          | 19896/22490 [1:08:54<08:50,  4.89it/s]










 89%|████████████████████████████████████████████████████████████████████████████████          | 19994/22490 [1:09:14<08:30,  4.89it/s]











 89%|████████████████████████████████████████████████████████████████████████████████▍         | 20101/22490 [1:09:36<08:10,  4.88it/s]










 90%|████████████████████████████████████████████████████████████████████████████████▊         | 20199/22490 [1:09:56<07:45,  4.92it/s]




 90%|████████████████████████████████████████████████████████████████████████████████▉         | 20240/22490 [1:10:05<07:37,  4.91it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
 90%|█████████████████████████████████████████████████████████████████████████████████         | 20241/22490 [1:10:05<09:15,  4.05it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([128, 103, 103])) that is different to the input size (torch.Size([128, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale






 90%|█████████████████████████████████████████████████████████████████████████████████▎        | 20304/22490 [1:10:22<07:24,  4.92it/s]










 91%|█████████████████████████████████████████████████████████████████████████████████▋        | 20402/22490 [1:10:42<07:05,  4.91it/s]










 91%|██████████████████████████████████████████████████████████████████████████████████        | 20498/22490 [1:11:02<06:45,  4.92it/s]










 92%|██████████████████████████████████████████████████████████████████████████████████▍       | 20596/22490 [1:11:22<06:24,  4.92it/s]










 92%|██████████████████████████████████████████████████████████████████████████████████▊       | 20694/22490 [1:11:42<06:05,  4.92it/s]











 92%|███████████████████████████████████████████████████████████████████████████████████▏      | 20803/22490 [1:12:04<05:43,  4.91it/s]










 93%|███████████████████████████████████████████████████████████████████████████████████▋      | 20901/22490 [1:12:24<05:23,  4.91it/s]










 93%|████████████████████████████████████████████████████████████████████████████████████      | 20999/22490 [1:12:44<05:03,  4.91it/s]










 94%|████████████████████████████████████████████████████████████████████████████████████▍     | 21097/22490 [1:13:04<04:43,  4.91it/s]










 94%|████████████████████████████████████████████████████████████████████████████████████▊     | 21195/22490 [1:13:25<04:23,  4.91it/s]











 95%|█████████████████████████████████████████████████████████████████████████████████████▏    | 21303/22490 [1:13:47<04:01,  4.91it/s]










 95%|█████████████████████████████████████████████████████████████████████████████████████▋    | 21399/22490 [1:14:06<03:42,  4.90it/s]










 96%|██████████████████████████████████████████████████████████████████████████████████████    | 21497/22490 [1:14:26<03:22,  4.91it/s]










 96%|██████████████████████████████████████████████████████████████████████████████████████▍   | 21595/22490 [1:14:47<03:02,  4.91it/s]











 96%|██████████████████████████████████████████████████████████████████████████████████████▊   | 21702/22490 [1:15:08<02:41,  4.89it/s]










 97%|███████████████████████████████████████████████████████████████████████████████████████▏  | 21800/22490 [1:15:29<02:20,  4.90it/s]










 97%|███████████████████████████████████████████████████████████████████████████████████████▋  | 21898/22490 [1:15:49<02:00,  4.89it/s]










 98%|████████████████████████████████████████████████████████████████████████████████████████  | 21995/22490 [1:16:09<01:41,  4.88it/s]











 98%|████████████████████████████████████████████████████████████████████████████████████████▍ | 22103/22490 [1:16:31<01:19,  4.89it/s]










 99%|████████████████████████████████████████████████████████████████████████████████████████▊ | 22200/22490 [1:16:51<00:59,  4.91it/s]










 99%|█████████████████████████████████████████████████████████████████████████████████████████▏| 22298/22490 [1:17:11<00:39,  4.90it/s]










100%|█████████████████████████████████████████████████████████████████████████████████████████▌| 22396/22490 [1:17:31<00:19,  4.90it/s]









100%|█████████████████████████████████████████████████████████████████████████████████████████▉| 22489/22490 [1:17:50<00:00,  4.93it/s]/home/alham.fikri/farid/lingualchemy/src/fusion_models.py:83: UserWarning: Using a target size (torch.Size([106, 103, 103])) that is different to the input size (torch.Size([106, 103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_uriel = F.mse_loss(projected_pooled_output.unsqueeze(-1), correct_uriel_vectors) * self.scale
100%|██████████████████████████████████████████████████████████████████████████████████████████| 22490/22490 [1:17:50<00:00,  3.54it/s]

100%|██████████████████████████████████████████████████████████████████████████████████████████| 22490/22490 [1:17:54<00:00,  4.81it/s]
Testing lang af-ZA: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.52it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang am-ET: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang ar-SA: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang az-AZ: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.66it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang bn-BD: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang ca-ES: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang cy-GB: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.66it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang da-DK: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang de-DE: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang el-GR: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang en-US: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang es-ES: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang fa-IR: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang fi-FI: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang fr-FR: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.66it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang he-IL: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.55it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang hi-IN: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.68it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Testing lang hu-HU: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang hy-AM: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang is-IS:   0%|                                                                                       | 0/47 [00:00<?, ?it/s]
/home/alham.fikri/mambaforge/envs/venvadapt/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Testing lang is-IS:  72%|████████████████████████████████████████████████████████▍                     | 34/47 [00:02<00:00, 16.53it/s]
Testing lang it-IT:  38%|█████████████████████████████▊                                                | 18/47 [00:01<00:01, 16.53it/s]
Testing lang ja-JP:   9%|██████▋                                                                        | 4/47 [00:00<00:02, 16.53it/s]
Testing lang ja-JP:  77%|███████████████████████████████████████████████████████████▋                  | 36/47 [00:02<00:00, 16.53it/s]
Testing lang jv-ID:  47%|████████████████████████████████████▌                                         | 22/47 [00:01<00:01, 16.53it/s]
Testing lang ka-GE:  13%|██████████                                                                     | 6/47 [00:00<00:02, 16.53it/s]
Testing lang ka-GE:  81%|███████████████████████████████████████████████████████████████               | 38/47 [00:02<00:00, 16.53it/s]
Testing lang km-KH:  51%|███████████████████████████████████████▊                                      | 24/47 [00:01<00:01, 16.52it/s]
Testing lang kn-IN:  17%|█████████████▍                                                                 | 8/47 [00:00<00:02, 16.53it/s]
Testing lang kn-IN:  85%|██████████████████████████████████████████████████████████████████▍           | 40/47 [00:02<00:00, 16.53it/s]
Testing lang ko-KR:  51%|███████████████████████████████████████▊                                      | 24/47 [00:01<00:01, 16.53it/s]
Testing lang lv-LV:  21%|████████████████▌                                                             | 10/47 [00:00<00:02, 16.52it/s]
Testing lang lv-LV:  89%|█████████████████████████████████████████████████████████████████████▋        | 42/47 [00:02<00:00, 16.53it/s]
Testing lang ml-IN:  55%|███████████████████████████████████████████▏                                  | 26/47 [00:01<00:01, 16.53it/s]
Testing lang mn-MN:  21%|████████████████▌                                                             | 10/47 [00:00<00:02, 16.43it/s]
Testing lang mn-MN:  94%|█████████████████████████████████████████████████████████████████████████     | 44/47 [00:02<00:00, 16.51it/s]
Testing lang ms-MY:  60%|██████████████████████████████████████████████▍                               | 28/47 [00:01<00:01, 16.53it/s]
Testing lang my-MM:  26%|███████████████████▉                                                          | 12/47 [00:00<00:02, 16.49it/s]
Testing lang my-MM:  94%|█████████████████████████████████████████████████████████████████████████     | 44/47 [00:02<00:00, 16.51it/s]
Testing lang nb-NO:  60%|██████████████████████████████████████████████▍                               | 28/47 [00:01<00:01, 16.53it/s]
Testing lang nl-NL:  26%|███████████████████▉                                                          | 12/47 [00:00<00:02, 16.52it/s]
Testing lang nl-NL:  94%|█████████████████████████████████████████████████████████████████████████     | 44/47 [00:02<00:00, 16.53it/s]
Testing lang pl-PL:  60%|██████████████████████████████████████████████▍                               | 28/47 [00:01<00:01, 16.53it/s]
Testing lang pt-PT:  26%|███████████████████▉                                                          | 12/47 [00:00<00:02, 16.53it/s]
Testing lang pt-PT:  94%|█████████████████████████████████████████████████████████████████████████     | 44/47 [00:02<00:00, 16.53it/s]
Testing lang ro-RO:  60%|██████████████████████████████████████████████▍                               | 28/47 [00:01<00:01, 16.52it/s]
Testing lang ru-RU:  26%|███████████████████▉                                                          | 12/47 [00:00<00:02, 16.52it/s]
Testing lang ru-RU:  94%|█████████████████████████████████████████████████████████████████████████     | 44/47 [00:02<00:00, 16.53it/s]
Testing lang sl-SL:  60%|██████████████████████████████████████████████▍                               | 28/47 [00:01<00:01, 16.52it/s]
Testing lang sq-AL:  21%|████████████████▌                                                             | 10/47 [00:00<00:02, 16.51it/s]
Testing lang sq-AL:  94%|█████████████████████████████████████████████████████████████████████████     | 44/47 [00:02<00:00, 16.52it/s]
Testing lang sv-SE:  60%|██████████████████████████████████████████████▍                               | 28/47 [00:01<00:01, 16.53it/s]
Testing lang sw-KE:  21%|████████████████▌                                                             | 10/47 [00:00<00:02, 16.53it/s]
Testing lang sw-KE:  94%|█████████████████████████████████████████████████████████████████████████     | 44/47 [00:02<00:00, 16.53it/s]
Testing lang ta-IN:  55%|███████████████████████████████████████████▏                                  | 26/47 [00:01<00:01, 16.52it/s]
Testing lang te-IN:  17%|█████████████▍                                                                 | 8/47 [00:00<00:02, 16.52it/s]
Testing lang te-IN:  89%|█████████████████████████████████████████████████████████████████████▋        | 42/47 [00:02<00:00, 16.52it/s]
Testing lang th-TH:  51%|███████████████████████████████████████▊                                      | 24/47 [00:01<00:01, 16.48it/s]
Testing lang tl-PH:  13%|██████████                                                                     | 6/47 [00:00<00:02, 16.52it/s]
Testing lang tl-PH:  85%|██████████████████████████████████████████████████████████████████▍           | 40/47 [00:02<00:00, 16.52it/s]
Testing lang tr-TR:  43%|█████████████████████████████████▏                                            | 20/47 [00:01<00:01, 16.53it/s]
Testing lang ur-PK:   9%|██████▋                                                                        | 4/47 [00:00<00:02, 16.51it/s]
Testing lang ur-PK:  81%|███████████████████████████████████████████████████████████████               | 38/47 [00:02<00:00, 16.52it/s]
Testing lang vi-VN:  43%|█████████████████████████████████▏                                            | 20/47 [00:01<00:01, 16.52it/s]
Testing lang zh-CN:   4%|███▎                                                                           | 2/47 [00:00<00:02, 16.48it/s]
Testing lang zh-CN:  77%|███████████████████████████████████████████████████████████▋                  | 36/47 [00:02<00:00, 16.53it/s]
Testing lang zh-TW:  38%|█████████████████████████████▊                                                | 18/47 [00:01<00:01, 16.53it/s]
Testing lang zh-TW: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
Testing lang zh-TW: 100%|██████████████████████████████████████████████████████████████████████████████| 47/47 [00:02<00:00, 16.69it/s]
{'af-ZA': {'precision_macro': 0.5993528768808586, 'precision_micro': 0.6049092131809012, 'recall_macro': 0.5474307893339916, 'recall_micro': 0.6049092131809012, 'f1_macro': 0.543242541580372, 'f1_micro': 0.6049092131809012, 'accuracy': 0.6049092131809012}, 'am-ET': {'precision_macro': 0.582158287315224, 'precision_micro': 0.31002017484868866, 'recall_macro': 0.2858831280093154, 'recall_micro': 0.31002017484868866, 'f1_macro': 0.3536805532068697, 'f1_micro': 0.31002017484868866, 'accuracy': 0.31002017484868866}, 'ar-SA': {'precision_macro': 0.6752429810863596, 'precision_micro': 0.47422102667563326, 'recall_macro': 0.44906996580985786, 'recall_micro': 0.47422102667563326, 'f1_macro': 0.516179914186618, 'f1_micro': 0.47422102667563326, 'accuracy': 0.47422102667563326}, 'az-AZ': {'precision_macro': 0.6541708338561898, 'precision_micro': 0.5203429724277068, 'recall_macro': 0.47661646349105047, 'recall_micro': 0.5203429724277068, 'f1_macro': 0.5312677384196184, 'f1_micro': 0.5203429724277068, 'accuracy': 0.5203429724277068}, 'bn-BD': {'precision_macro': 0.6833149490117478, 'precision_micro': 0.5829186281102892, 'recall_macro': 0.5424481871352532, 'recall_micro': 0.5829186281102892, 'f1_macro': 0.5869412626618625, 'f1_micro': 0.5829186281102892, 'accuracy': 0.5829186281102892}, 'ca-ES': {'precision_macro': 0.6894549852085989, 'precision_micro': 0.6140999775835014, 'recall_macro': 0.5727246980105242, 'recall_micro': 0.6140999775835014, 'f1_macro': 0.6097042564028304, 'f1_micro': 0.6140999775835014, 'accuracy': 0.6140999775835014}, 'cy-GB': {'precision_macro': 0.6508396308670644, 'precision_micro': 0.5639830915553847, 'recall_macro': 0.5189168618672196, 'recall_micro': 0.5639830915553847, 'f1_macro': 0.5603317383947994, 'f1_micro': 0.5639830915553847, 'accuracy': 0.5639830915553847}, 'da-DK': {'precision_macro': 0.6538609824697865, 'precision_micro': 0.5864156018829859, 'recall_macro': 0.5358903864454265, 'recall_micro': 0.5864156018829859, 'f1_macro': 0.5735006678330755, 'f1_micro': 0.5864156018829859, 'accuracy': 0.5864156018829859}, 'de-DE': {'precision_macro': 0.6700515742711629, 'precision_micro': 0.6155196891578869, 'recall_macro': 0.5682162962487138, 'recall_micro': 0.6155196891578869, 'f1_macro': 0.6000335908907104, 'f1_micro': 0.6155196891578869, 'accuracy': 0.6155196891578869}, 'el-GR': {'precision_macro': 0.6834784195093281, 'precision_micro': 0.6381304640215198, 'recall_macro': 0.5932335667561002, 'recall_micro': 0.6381304640215198, 'f1_macro': 0.6213094787964883, 'f1_micro': 0.6381304640215198, 'accuracy': 0.6381304640215198}, 'en-US': {'precision_macro': 0.6971335759091434, 'precision_micro': 0.659992663691386, 'recall_macro': 0.6169092550282768, 'recall_micro': 0.659992663691386, 'f1_macro': 0.6409616016933274, 'f1_micro': 0.659992663691386, 'accuracy': 0.659992663691386}, 'es-ES': {'precision_macro': 0.7069518118878121, 'precision_micro': 0.6765579466487335, 'recall_macro': 0.6347835108174793, 'recall_micro': 0.6765579466487335, 'f1_macro': 0.6557164337228956, 'f1_micro': 0.6765579466487335, 'accuracy': 0.6765579466487335}, 'fa-IR': {'precision_macro': 0.6965595569555539, 'precision_micro': 0.6731415860534892, 'recall_macro': 0.6275791389689964, 'recall_micro': 0.6731415860534892, 'f1_macro': 0.6472283085516585, 'f1_micro': 0.6731415860534892, 'accuracy': 0.6731415860534892}, 'fi-FI': {'precision_macro': 0.7038442816570541, 'precision_micro': 0.6858728023825535, 'recall_macro': 0.6408215002877312, 'recall_micro': 0.6858728023825535, 'f1_macro': 0.6583211186696044, 'f1_micro': 0.6858728023825535, 'accuracy': 0.6858728023825535}, 'fr-FR': {'precision_macro': 0.7118158794078708, 'precision_micro': 0.6982066801165658, 'recall_macro': 0.6540063211952413, 'recall_micro': 0.6982066801165658, 'f1_macro': 0.669595248874595, 'f1_micro': 0.6982066801165658, 'accuracy': 0.6982066801165658}, 'he-IL': {'precision_macro': 0.7002330882794779, 'precision_micro': 0.687352891728312, 'recall_macro': 0.6400319884041863, 'recall_micro': 0.687352891728312, 'f1_macro': 0.6564636715815068, 'f1_micro': 0.687352891728312, 'accuracy': 0.687352891728312}, 'hi-IN': {'precision_macro': 0.7044226884820209, 'precision_micro': 0.6965465406068277, 'recall_macro': 0.649573416991063, 'recall_micro': 0.6965465406068277, 'f1_macro': 0.6641914224021487, 'f1_micro': 0.6965465406068277, 'accuracy': 0.6965465406068277}, 'hu-HU': {'precision_macro': 0.709561568697654, 'precision_micro': 0.7048867966823582, 'recall_macro': 0.6586155091553143, 'recall_micro': 0.7048867966823582, 'f1_macro': 0.671696435281838, 'f1_micro': 0.7048867966823582, 'accuracy': 0.7048867966823582}, 'hy-AM': {'precision_macro': 0.7137490249005879, 'precision_micro': 0.712065975294659, 'recall_macro': 0.6655439975570763, 'recall_micro': 0.712065975294659, 'f1_macro': 0.6778438962056661, 'f1_micro': 0.712065975294659, 'accuracy': 0.712065975294659}, 'id-ID': {'precision_macro': 0.7190860969449997, 'precision_micro': 0.7194687289845326, 'recall_macro': 0.6741035820274975, 'recall_micro': 0.7194687289845326, 'f1_macro': 0.6851704677381054, 'f1_micro': 0.7194687289845326, 'accuracy': 0.7194687289845326}, 'is-IS': {'precision_macro': 0.722526579221831, 'precision_micro': 0.7255900342652192, 'recall_macro': 0.6810492455187579, 'recall_micro': 0.7255900342652192, 'f1_macro': 0.6906819533754543, 'f1_micro': 0.7255900342652192, 'accuracy': 0.7255900342652192}, 'it-IT': {'precision_macro': 0.7207387783401603, 'precision_micro': 0.726065293146665, 'recall_macro': 0.6808136742275742, 'recall_micro': 0.726065293146665, 'f1_macro': 0.6895354957204826, 'f1_micro': 0.726065293146665, 'accuracy': 0.726065293146665}, 'ja-JP': {'precision_macro': 0.7247309829117913, 'precision_micro': 0.7321277155638723, 'recall_macro': 0.686894083549522, 'recall_micro': 0.7321277155638723, 'f1_macro': 0.6948781179790825, 'f1_micro': 0.7321277155638723, 'accuracy': 0.7321277155638723}, 'jv-ID': {'precision_macro': 0.7271713416157443, 'precision_micro': 0.7364800493162968, 'recall_macro': 0.69218238074448, 'recall_micro': 0.7364800493162968, 'f1_macro': 0.6988050653917434, 'f1_micro': 0.7364800493162967, 'accuracy': 0.7364800493162968}, 'ka-GE': {'precision_macro': 0.727256637126791, 'precision_micro': 0.7386146603900471, 'recall_macro': 0.6943369148731853, 'recall_micro': 0.7386146603900471, 'f1_macro': 0.7001672578683513, 'f1_micro': 0.7386146603900471, 'accuracy': 0.7386146603900471}, 'km-KH': {'precision_macro': 0.7220921383624103, 'precision_micro': 0.7121980238994361, 'recall_macro': 0.6691671955229451, 'recall_micro': 0.7121980238994361, 'f1_macro': 0.6820603817286813, 'f1_micro': 0.712198023899436, 'accuracy': 0.7121980238994361}, 'kn-IN': {'precision_macro': 0.7120558123729771, 'precision_micro': 0.7016986724451418, 'recall_macro': 0.6567648309678613, 'recall_micro': 0.7016986724451418, 'f1_macro': 0.6708903960708764, 'f1_micro': 0.7016986724451418, 'accuracy': 0.7016986724451418}, 'ko-KR': {'precision_macro': 0.7150708410661574, 'precision_micro': 0.7073085791142281, 'recall_macro': 0.6621350343917576, 'recall_micro': 0.7073085791142281, 'f1_macro': 0.6754471898186022, 'f1_micro': 0.707308579114228, 'accuracy': 0.7073085791142281}, 'lv-LV': {'precision_macro': 0.7176513017102206, 'precision_micro': 0.7119518586369223, 'recall_macro': 0.6677560920732584, 'recall_micro': 0.7119518586369223, 'f1_macro': 0.6798609522518791, 'f1_micro': 0.7119518586369223, 'accuracy': 0.7119518586369223}, 'ml-IN': {'precision_macro': 0.7092755113480168, 'precision_micro': 0.7002802062317866, 'recall_macro': 0.6539262988535472, 'recall_micro': 0.7002802062317866, 'f1_macro': 0.6684456635026803, 'f1_micro': 0.7002802062317866, 'accuracy': 0.7002802062317866}, 'mn-MN': {'precision_macro': 0.700837097070242, 'precision_micro': 0.6872789986333167, 'recall_macro': 0.6404842677928166, 'recall_micro': 0.6872789986333167, 'f1_macro': 0.6568784068819641, 'f1_micro': 0.6872789986333167, 'accuracy': 0.6872789986333167}, 'ms-MY': {'precision_macro': 0.6993562133622202, 'precision_micro': 0.687216291190316, 'recall_macro': 0.6402168531723541, 'recall_micro': 0.687216291190316, 'f1_macro': 0.6559861647073986, 'f1_micro': 0.687216291190316, 'accuracy': 0.687216291190316}, 'my-MM': {'precision_macro': 0.7017633705777152, 'precision_micro': 0.691640683906992, 'recall_macro': 0.6449233886080861, 'recall_micro': 0.691640683906992, 'f1_macro': 0.6598573366747698, 'f1_micro': 0.691640683906992, 'accuracy': 0.691640683906992}, 'nb-NO': {'precision_macro': 0.7000128467627983, 'precision_micro': 0.6924720123422604, 'recall_macro': 0.645140671406306, 'recall_micro': 0.6924720123422604, 'f1_macro': 0.6593532079002713, 'f1_micro': 0.6924720123422604, 'accuracy': 0.6924720123422604}, 'nl-NL': {'precision_macro': 0.7001438023423636, 'precision_micro': 0.6941685080219041, 'recall_macro': 0.6463271361584415, 'recall_micro': 0.6941685080219041, 'f1_macro': 0.6601770348910919, 'f1_micro': 0.6941685080219041, 'accuracy': 0.6941685080219041}, 'pl-PL': {'precision_macro': 0.6967079762384016, 'precision_micro': 0.6929780318314279, 'recall_macro': 0.643871439665564, 'recall_micro': 0.6929780318314279, 'f1_macro': 0.6573308273906342, 'f1_micro': 0.6929780318314279, 'accuracy': 0.6929780318314279}, 'pt-PT': {'precision_macro': 0.6998106519203708, 'precision_micro': 0.6975044984459914, 'recall_macro': 0.6485030531428653, 'recall_micro': 0.6975044984459914, 'f1_macro': 0.6614878766679028, 'f1_micro': 0.6975044984459914, 'accuracy': 0.6975044984459914}, 'ro-RO': {'precision_macro': 0.696836232183694, 'precision_micro': 0.6953509361837681, 'recall_macro': 0.6461363316244056, 'recall_micro': 0.6953509361837681, 'f1_macro': 0.6587839044842976, 'f1_micro': 0.6953509361837681, 'accuracy': 0.6953509361837681}, 'ru-RU': {'precision_macro': 0.6998351485374756, 'precision_micro': 0.699679271636232, 'recall_macro': 0.6509344031570062, 'recall_micro': 0.699679271636232, 'f1_macro': 0.6629642191315143, 'f1_micro': 0.699679271636232, 'accuracy': 0.699679271636232}, 'sl-SL': {'precision_macro': 0.6969638306079873, 'precision_micro': 0.6960659045057163, 'recall_macro': 0.6467815525427416, 'recall_micro': 0.6960659045057163, 'f1_macro': 0.659336818879596, 'f1_micro': 0.6960659045057163, 'accuracy': 0.6960659045057163}, 'sq-AL': {'precision_macro': 0.6930770126345018, 'precision_micro': 0.6913904243279151, 'recall_macro': 0.6416201484037714, 'recall_micro': 0.6913904243279151, 'f1_macro': 0.6547106798783133, 'f1_micro': 0.6913904243279151, 'accuracy': 0.6913904243279151}, 'sv-SE': {'precision_macro': 0.6912176793933279, 'precision_micro': 0.6904922022608639, 'recall_macro': 0.6403446397033817, 'recall_micro': 0.6904922022608639, 'f1_macro': 0.6530453278297955, 'f1_micro': 0.6904922022608639, 'accuracy': 0.6904922022608639}, 'sw-KE': {'precision_macro': 0.6836346532441229, 'precision_micro': 0.6800409752740808, 'recall_macro': 0.6301381361313764, 'recall_micro': 0.6800409752740808, 'f1_macro': 0.6436837358256664, 'f1_micro': 0.6800409752740808, 'accuracy': 0.6800409752740808}, 'ta-IN': {'precision_macro': 0.6784523377489342, 'precision_micro': 0.6734502048052822, 'recall_macro': 0.6232147447277423, 'recall_micro': 0.6734502048052822, 'f1_macro': 0.637522814944827, 'f1_micro': 0.6734502048052822, 'accuracy': 0.6734502048052822}, 'te-IN': {'precision_macro': 0.6738074565166575, 'precision_micro': 0.667503549278936, 'recall_macro': 0.6163765146361441, 'recall_micro': 0.667503549278936, 'f1_macro': 0.6315401902851218, 'f1_micro': 0.667503549278936, 'accuracy': 0.667503549278936}, 'th-TH': {'precision_macro': 0.6646850443878198, 'precision_micro': 0.6590450571620713, 'recall_macro': 0.6076096000690672, 'recall_micro': 0.6590450571620713, 'f1_macro': 0.6220966019923536, 'f1_micro': 0.6590450571620713, 'accuracy': 0.6590450571620713}, 'tl-PH': {'precision_macro': 0.6606504581939036, 'precision_micro': 0.6535720928901544, 'recall_macro': 0.6021176763278697, 'recall_micro': 0.6535720928901544, 'f1_macro': 0.6171489714576999, 'f1_micro': 0.6535720928901544, 'accuracy': 0.6535720928901544}, 'tr-TR': {'precision_macro': 0.6636430370907024, 'precision_micro': 0.6576790517821116, 'recall_macro': 0.6066945677324816, 'recall_micro': 0.6576790517821116, 'f1_macro': 0.6211488461428089, 'f1_micro': 0.6576790517821116, 'accuracy': 0.6576790517821116}, 'ur-PK': {'precision_macro': 0.659744964248599, 'precision_micro': 0.6536170621577481, 'recall_macro': 0.6018500503879174, 'recall_micro': 0.6536170621577481, 'f1_macro': 0.6165859052597145, 'f1_micro': 0.6536170621577481, 'accuracy': 0.6536170621577481}, 'vi-VN': {'precision_macro': 0.6626015240365561, 'precision_micro': 0.6577000672494956, 'recall_macro': 0.6061146295802041, 'recall_micro': 0.6577000672494956, 'f1_macro': 0.6204407419872201, 'f1_micro': 0.6577000672494956, 'accuracy': 0.6577000672494956}, 'zh-CN': {'precision_macro': 0.6653261470921398, 'precision_micro': 0.6616691061091552, 'recall_macro': 0.6101518163457895, 'recall_micro': 0.6616691061091552, 'f1_macro': 0.6241080549968069, 'f1_micro': 0.6616691061091552, 'accuracy': 0.6616691061091552}, 'zh-TW': {'precision_macro': 0.6678288656043605, 'precision_micro': 0.6651880399358543, 'recall_macro': 0.6140120742895352, 'recall_micro': 0.6651880399358543, 'f1_macro': 0.6275502773458115, 'f1_micro': 0.6651880399358543, 'accuracy': 0.6651880399358543}}